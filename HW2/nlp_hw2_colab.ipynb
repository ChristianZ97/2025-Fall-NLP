{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/NLP/HW2/"
      ],
      "metadata": {
        "id": "c5IQrxqggOyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02a357e-f603-4063-8576-0c298c1f91d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/NLP/HW2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5myC5GUgLPO"
      },
      "source": [
        "# LSTM-arithmetic\n",
        "\n",
        "## Dataset\n",
        "- [Arithmetic dataset](https://drive.google.com/file/d/1cMuL3hF9jefka9RyF4gEBIGGeFGZYHE-/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j5rPNRD3gLPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d199fec9-d989-4058-d2a6-21795442bdb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Collecting opencc\n",
            "  Downloading OpenCC-1.1.9-cp312-cp312-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading OpenCC-1.1.9-cp312-cp312-manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencc\n",
            "Successfully installed opencc-1.1.9\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.7.2\n"
          ]
        }
      ],
      "source": [
        "! pip install seaborn\n",
        "! pip install opencc\n",
        "! pip install -U scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.utils.rnn\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import opencc\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_path = './data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r_Xg9wQ5gLPQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "762a6fbf-89a0-49bd-9135-bde315cb8a45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           src   tgt\n",
              "0  14*(43+20)=   882\n",
              "1     (6+1)*5=    35\n",
              "2    13+32+29=    74\n",
              "3   31*(3-11)=  -248\n",
              "4     24*49+1=  1177"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e83b9e40-15b2-4e70-96fb-bae555302f73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14*(43+20)=</td>\n",
              "      <td>882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(6+1)*5=</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13+32+29=</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31*(3-11)=</td>\n",
              "      <td>-248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24*49+1=</td>\n",
              "      <td>1177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e83b9e40-15b2-4e70-96fb-bae555302f73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e83b9e40-15b2-4e70-96fb-bae555302f73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e83b9e40-15b2-4e70-96fb-bae555302f73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2a171429-c704-4e3e-9454-59ae1a599d7f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a171429-c704-4e3e-9454-59ae1a599d7f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2a171429-c704-4e3e-9454-59ae1a599d7f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_train = pd.read_csv(os.path.join(data_path, 'arithmetic_train.csv'))\n",
        "df_eval = pd.read_csv(os.path.join(data_path, 'arithmetic_eval.csv'))\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1s7Bzf6DgLPQ"
      },
      "outputs": [],
      "source": [
        "# transform the input data to string\n",
        "df_train['tgt'] = df_train['tgt'].apply(lambda x: str(x))\n",
        "df_train['src'] = df_train['src'].add(df_train['tgt'])\n",
        "df_train['len'] = df_train['src'].apply(lambda x: len(x))\n",
        "\n",
        "df_eval['tgt'] = df_eval['tgt'].apply(lambda x: str(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy0PcMfUgLPQ"
      },
      "source": [
        "# Build Dictionary\n",
        " - The model cannot perform calculations directly with plain text.\n",
        " - Convert all text (numbers/symbols) into numerical representations.\n",
        " - Special tokens\n",
        "    - '&lt;pad&gt;'\n",
        "        - Each sentence within a batch may have different lengths.\n",
        "        - The length is padded with '&lt;pad&gt;' to match the longest sentence in the batch.\n",
        "    - '&lt;eos&gt;'\n",
        "        - Specifies the end of the generated sequence.\n",
        "        - Without '&lt;eos&gt;', the model will not know when to stop generating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LEV3wNobgLPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588e54a6-e3f6-4417-91b1-0c4af1a253a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size18\n"
          ]
        }
      ],
      "source": [
        "char_to_id = {}\n",
        "id_to_char = {}\n",
        "\n",
        "# write your code here\n",
        "# Build a dictionary and give every token in the train dataset an id\n",
        "# The dictionary should contain <eos> and <pad>\n",
        "# char_to_id is to conver charactors to ids, while id_to_char is the opposite\n",
        "\n",
        "all_chars = [\n",
        "    \"0\",\n",
        "    \"1\",\n",
        "    \"2\",\n",
        "    \"3\",\n",
        "    \"4\",\n",
        "    \"5\",\n",
        "    \"6\",\n",
        "    \"7\",\n",
        "    \"8\",\n",
        "    \"9\",\n",
        "    \"+\",\n",
        "    \"-\",\n",
        "    \"*\",\n",
        "    \"(\",\n",
        "    \")\",\n",
        "    \"=\",\n",
        "]\n",
        "special_tokens = [\"<pad>\", \"<eos>\"]\n",
        "all_tokens = special_tokens + all_chars\n",
        "\n",
        "char_to_id = {char: idx for idx, char in enumerate(all_tokens)}\n",
        "id_to_char = {idx: char for idx, char in enumerate(all_tokens)}\n",
        "\n",
        "vocab_size = len(char_to_id)\n",
        "print('Vocab size{}'.format(vocab_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97A5G4GmgLPR"
      },
      "source": [
        "# Data Preprocessing\n",
        " - The data is processed into the format required for the model's input and output. (End with \\<eos\\> token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9KhFKEcYgLPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "69808aee-928d-465e-c553-18a21d5917b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              src   tgt  len  \\\n",
              "0  14*(43+20)=882   882   14   \n",
              "1      (6+1)*5=35    35   10   \n",
              "2     13+32+29=74    74   11   \n",
              "3  31*(3-11)=-248  -248   14   \n",
              "4    24*49+1=1177  1177   12   \n",
              "\n",
              "                                        char_id_list  \\\n",
              "0  [3, 6, 14, 15, 6, 5, 12, 4, 2, 16, 17, 10, 10,...   \n",
              "1             [15, 8, 12, 3, 16, 14, 7, 17, 5, 7, 1]   \n",
              "2           [3, 5, 12, 5, 4, 12, 4, 11, 17, 9, 6, 1]   \n",
              "3  [5, 3, 14, 15, 5, 13, 3, 3, 16, 17, 13, 4, 6, ...   \n",
              "4        [4, 6, 14, 6, 11, 12, 3, 17, 3, 3, 9, 9, 1]   \n",
              "\n",
              "                                     label_id_list  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 4, 1, 0]  \n",
              "1                [0, 0, 0, 0, 0, 0, 0, 5, 7, 1, 0]  \n",
              "2             [0, 0, 0, 0, 0, 0, 0, 0, 9, 6, 1, 0]  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 4, 6, 10, 1, 0]  \n",
              "4          [0, 0, 0, 0, 0, 0, 0, 3, 3, 9, 9, 1, 0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d47a4653-7c18-4f60-b6db-d56ad1d61065\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "      <th>len</th>\n",
              "      <th>char_id_list</th>\n",
              "      <th>label_id_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14*(43+20)=882</td>\n",
              "      <td>882</td>\n",
              "      <td>14</td>\n",
              "      <td>[3, 6, 14, 15, 6, 5, 12, 4, 2, 16, 17, 10, 10,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 4, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(6+1)*5=35</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>[15, 8, 12, 3, 16, 14, 7, 17, 5, 7, 1]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 5, 7, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13+32+29=74</td>\n",
              "      <td>74</td>\n",
              "      <td>11</td>\n",
              "      <td>[3, 5, 12, 5, 4, 12, 4, 11, 17, 9, 6, 1]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 9, 6, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31*(3-11)=-248</td>\n",
              "      <td>-248</td>\n",
              "      <td>14</td>\n",
              "      <td>[5, 3, 14, 15, 5, 13, 3, 3, 16, 17, 13, 4, 6, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 4, 6, 10, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24*49+1=1177</td>\n",
              "      <td>1177</td>\n",
              "      <td>12</td>\n",
              "      <td>[4, 6, 14, 6, 11, 12, 3, 17, 3, 3, 9, 9, 1]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 3, 9, 9, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d47a4653-7c18-4f60-b6db-d56ad1d61065')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d47a4653-7c18-4f60-b6db-d56ad1d61065 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d47a4653-7c18-4f60-b6db-d56ad1d61065');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0efa8407-0b8c-4685-8df0-d3b00b9073e7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0efa8407-0b8c-4685-8df0-d3b00b9073e7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0efa8407-0b8c-4685-8df0-d3b00b9073e7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "def data_preprocess(df: pd.DataFrame, char_to_id: dict) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    char_id_list = []\n",
        "    label_id_list = []\n",
        "    src_len_list = []\n",
        "\n",
        "    for sent in df[\"src\"]:\n",
        "        sent_len = len(sent)\n",
        "        sent = sent.split(\"=\")\n",
        "        sent_train = sent[0]\n",
        "        sent_tgt = sent[1]\n",
        "\n",
        "        char_id = []\n",
        "        label_id = []\n",
        "\n",
        "        # Input part before '='\n",
        "        for char in sent_train:\n",
        "            char_id.append(char_to_id[char])\n",
        "            label_id.append(char_to_id[\"<pad>\"])\n",
        "\n",
        "        # '=' symbol\n",
        "        char_id.append(char_to_id[\"=\"])\n",
        "        label_id.append(char_to_id[sent_tgt[0]])\n",
        "\n",
        "        # Answer part - each position predicts NEXT character\n",
        "        for i, char in enumerate(sent_tgt):\n",
        "            char_id.append(char_to_id[char])\n",
        "            if i < len(sent_tgt) - 1:\n",
        "                label_id.append(char_to_id[sent_tgt[i + 1]])\n",
        "            else:\n",
        "                label_id.append(char_to_id[\"<eos>\"])\n",
        "\n",
        "        #   0     +     0   =   0   <eos>\n",
        "        # <pad> <pad> <pad> 0 <eos> <pad>\n",
        "\n",
        "        # End of sequence token\n",
        "        char_id.append(char_to_id[\"<eos>\"])\n",
        "        label_id.append(char_to_id[\"<pad>\"])\n",
        "\n",
        "        src_len_list.append(sent_len)\n",
        "        char_id_list.append(char_id)\n",
        "        label_id_list.append(label_id)\n",
        "\n",
        "    df[\"len\"] = src_len_list\n",
        "    df[\"char_id_list\"] = char_id_list\n",
        "    df[\"label_id_list\"] = label_id_list\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df_train = data_preprocess(df_train, char_to_id)\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNAAzgaOgLPR"
      },
      "source": [
        "# Hyper Parameters\n",
        "\n",
        "|Hyperparameter|Meaning|Value|\n",
        "|-|-|-|\n",
        "|`batch_size`|Number of data samples in a single batch|64|\n",
        "|`epochs`|Total number of epochs to train|10|\n",
        "|`embed_dim`|Dimension of the word embeddings|256|\n",
        "|`hidden_dim`|Dimension of the hidden state in each timestep of the LSTM|256|\n",
        "|`lr`|Learning Rate|0.001|\n",
        "|`grad_clip`|To prevent gradient explosion in RNNs, restrict the gradient range|1|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Kji6-VvtgLPR"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "epochs = 5\n",
        "embed_dim = 256\n",
        "hidden_dim = 256\n",
        "lr = 0.0011554\n",
        "weight_decay = 0.0057802\n",
        "momentum = 0.98805\n",
        "grad_clip = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFsKozaQgLPR"
      },
      "source": [
        "# Data Batching\n",
        "- Use `torch.utils.data.Dataset` to create a data generation tool called  `dataset`.\n",
        "- The, use `torch.utils.data.DataLoader` to randomly sample from the `dataset` and group the samples into batches.\n",
        "\n",
        "- Example: 1+2-3=0\n",
        "    - Model input: 1 + 2 - 3 = 0\n",
        "    - Model output: / / / / / 0 &lt;eos&gt;  (the '/' can be replaced with &lt;pad&gt;)\n",
        "    - The key for the model's output is that the model does not need to predict the next character of the previous part. What matters is that once the model sees '=', it should start generating the answer, which is '0'. After generating the answer, it should also generate&lt;eos&gt;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Dt05Xo2zgLPR"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        # return the amount of data\n",
        "        # return # Write your code here\n",
        "\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Extract the input data x and the ground truth y from the data\n",
        "        # x = # Write your code here\n",
        "        # y = # Write your code here\n",
        "\n",
        "        x = self.sequences.iloc[index][\"char_id_list\"]\n",
        "        y = self.sequences.iloc[index][\"label_id_list\"]\n",
        "        return x, y\n",
        "\n",
        "# collate function, used to build dataloader\n",
        "def collate_fn(batch):\n",
        "    batch_x = [torch.tensor(data[0]) for data in batch]\n",
        "    batch_y = [torch.tensor(data[1]) for data in batch]\n",
        "    batch_x_lens = torch.LongTensor([len(x) for x in batch_x])\n",
        "    batch_y_lens = torch.LongTensor([len(y) for y in batch_y])\n",
        "\n",
        "    # Pad the input sequence\n",
        "    pad_batch_x = torch.nn.utils.rnn.pad_sequence(batch_x,\n",
        "                                                  batch_first=True,\n",
        "                                                  padding_value=char_to_id['<pad>'])\n",
        "\n",
        "    pad_batch_y = torch.nn.utils.rnn.pad_sequence(batch_y,\n",
        "                                                  batch_first=True,\n",
        "                                                  padding_value=char_to_id['<pad>'])\n",
        "\n",
        "    return pad_batch_x, pad_batch_y, batch_x_lens, batch_y_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "axMnxkNxgLPS"
      },
      "outputs": [],
      "source": [
        "ds_train = Dataset(df_train[['char_id_list', 'label_id_list']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WNx0Sin1gLPS"
      },
      "outputs": [],
      "source": [
        "# Build dataloader of train set and eval set, collate_fn is the collate function\n",
        "# dl_train = # Write your code here\n",
        "\n",
        "dl_train = torch.utils.data.DataLoader(\n",
        "    ds_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=os.cpu_count(),\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giM2n0iEgLPS"
      },
      "source": [
        "# Model Design\n",
        "\n",
        "## Execution Flow\n",
        "1. Convert all characters in the sentence into embeddings.\n",
        "2. Pass the embeddings through an LSTM sequentially.\n",
        "3. The output of the LSTM is passed into another LSTM, and additional layers can be added.\n",
        "4. The output from all time steps of the final LSTM is passed through a Fully Connected layer.\n",
        "5. The character corresponding to the maximum value across all output dimensions is selected as the next character.\n",
        "\n",
        "## Loss Function\n",
        "Since this is a classification task, Cross Entropy is used as the loss function.\n",
        "\n",
        "## Gradient Update\n",
        "Adam algorithm is used for gradient updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "188jLRzygLPS"
      },
      "outputs": [],
      "source": [
        "class CharRNN(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(CharRNN, self).__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,\n",
        "                                            embedding_dim=embed_dim,\n",
        "                                            padding_idx=char_to_id['<pad>'])\n",
        "\n",
        "        self.rnn_layer1 = torch.nn.LSTM(input_size=embed_dim,\n",
        "                                        hidden_size=hidden_dim,\n",
        "                                        batch_first=True)\n",
        "\n",
        "        self.rnn_layer2 = torch.nn.LSTM(input_size=hidden_dim,\n",
        "                                        hidden_size=hidden_dim,\n",
        "                                        batch_first=True)\n",
        "\n",
        "        self.linear = torch.nn.Sequential(torch.nn.Linear(in_features=hidden_dim,\n",
        "                                                          out_features=hidden_dim),\n",
        "                                          torch.nn.ReLU(),\n",
        "                                          torch.nn.Linear(in_features=hidden_dim,\n",
        "                                                          out_features=vocab_size))\n",
        "\n",
        "    def forward(self, batch_x, batch_x_lens):\n",
        "        return self.encoder(batch_x, batch_x_lens)\n",
        "\n",
        "    # The forward pass of the model\n",
        "    def encoder(self, batch_x, batch_x_lens):\n",
        "        batch_x = self.embedding(batch_x)\n",
        "\n",
        "        batch_x = torch.nn.utils.rnn.pack_padded_sequence(batch_x,\n",
        "                                                          batch_x_lens,\n",
        "                                                          batch_first=True,\n",
        "                                                          enforce_sorted=False)\n",
        "\n",
        "        batch_x, _ = self.rnn_layer1(batch_x)\n",
        "        batch_x, _ = self.rnn_layer2(batch_x)\n",
        "\n",
        "        batch_x, _ = torch.nn.utils.rnn.pad_packed_sequence(batch_x,\n",
        "                                                            batch_first=True)\n",
        "\n",
        "        batch_x = self.linear(batch_x)\n",
        "\n",
        "        return batch_x\n",
        "\n",
        "    def generator(self, start_char, max_len=200):\n",
        "\n",
        "        char_list = [char_to_id[c] for c in start_char]\n",
        "\n",
        "        next_char = None\n",
        "\n",
        "        while len(char_list) < max_len:\n",
        "            # Write your code here\n",
        "            # Pack the char_list to tensor\n",
        "            # Input the tensor to the embedding layer, LSTM layers, linear respectively\n",
        "            # y = # Obtain the next token prediction y\n",
        "\n",
        "            batch_x = torch.tensor(char_list).unsqueeze(0).to(device)\n",
        "            batch_x_len = torch.tensor([len(char_list)])\n",
        "            y = self.forward(batch_x, batch_x_len)\n",
        "            logits = y[0, -1]\n",
        "\n",
        "            # next_char = # Use argmax function to get the next token prediction\n",
        "\n",
        "            next_char = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "            if next_char == char_to_id['<eos>']:\n",
        "                break\n",
        "\n",
        "            char_list.append(next_char)\n",
        "\n",
        "        return [id_to_char[ch_id] for ch_id in char_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bjCOU0rIgLPS"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(2)\n",
        "\n",
        "\n",
        "# device = # Write your code here. Specify a device (cuda or cpu)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CharRNN(vocab_size,\n",
        "                embed_dim,\n",
        "                hidden_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p2819fjwgLPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0563cb98-cac2-40e7-c0cf-8499ed10de4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/KellerJordan/Muon\n",
            "  Cloning https://github.com/KellerJordan/Muon to /tmp/pip-req-build-gu93hn79\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/KellerJordan/Muon /tmp/pip-req-build-gu93hn79\n",
            "  Resolved https://github.com/KellerJordan/Muon to commit f90a42b28e00b8d9d2d05865fe90d9f39abcbcbd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: muon-optimizer\n",
            "  Building wheel for muon-optimizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for muon-optimizer: filename=muon_optimizer-0.1.0-py3-none-any.whl size=7144 sha256=88207f602b23918af47536aaa2ae4f3d7f0386de67a29ebb31d379269359146a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2nsu2mh/wheels/6e/33/94/64d18603ba0f39064aab523d6edf493c388cfb7419bb5c9043\n",
            "Successfully built muon-optimizer\n",
            "Installing collected packages: muon-optimizer\n",
            "Successfully installed muon-optimizer-0.1.0\n"
          ]
        }
      ],
      "source": [
        "# criterion = # Write your code here. Cross-entropy loss function. The loss function should ignore <pad>\n",
        "# optimizer = # Write your code here. Use Adam or AdamW for Optimizer\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=char_to_id[\"<pad>\"])\n",
        "\n",
        "\n",
        "! pip install git+https://github.com/KellerJordan/Muon\n",
        "from muon import SingleDeviceMuon\n",
        "\n",
        "muon_params = [\n",
        "    p\n",
        "    for layer in [model.rnn_layer1, model.rnn_layer2]\n",
        "    for p in layer.parameters()\n",
        "    if p.ndim >= 2\n",
        "]\n",
        "\n",
        "adamw_params = [\n",
        "    *model.embedding.parameters(),\n",
        "    *[\n",
        "        p\n",
        "        for layer in [model.rnn_layer1, model.rnn_layer2]\n",
        "        for p in layer.parameters()\n",
        "        if p.ndim < 2\n",
        "    ],\n",
        "    *model.linear.parameters(),\n",
        "]\n",
        "\n",
        "optimizers = [\n",
        "    SingleDeviceMuon(muon_params, lr=lr, momentum=momentum),\n",
        "    torch.optim.AdamW(adamw_params, lr=lr, weight_decay=weight_decay),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl5PjTj2gLPS"
      },
      "source": [
        "# Training\n",
        "1. The outer `for` loop controls the `epoch`\n",
        "    1. The inner `for` loop uses `data_loader` to retrieve batches.\n",
        "        1. Pass the batch to the `model` for training.\n",
        "        2. Compare the predicted results `batch_pred_y` with the true labels `batch_y` using Cross Entropy to calculate the loss `loss`\n",
        "        3. Use `loss.backward` to automatically compute the gradients.\n",
        "        4. Use `torch.nn.utils.clip_grad_value_` to limit the gradient values between `-grad_clip` &lt; and &lt; `grad_clip`.\n",
        "        5. Use `optimizer.step()` to update the model (backpropagation).\n",
        "2.  After every `1000` batches, output the current loss to monitor whether it is converging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xl26g2B0gLPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22922e0d-a4c4-4890-f664-082d992ba9fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1: 100%|██████████| 9255/9255 [05:12<00:00, 29.65it/s, loss=0.324]\n",
            "Validation epoch 1: 263250it [34:35, 126.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6449344729344729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2: 100%|██████████| 9255/9255 [04:52<00:00, 31.69it/s, loss=0.184]\n",
            "Validation epoch 2: 263250it [32:23, 135.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.750579297245964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3: 100%|██████████| 9255/9255 [04:52<00:00, 31.62it/s, loss=0.129]\n",
            "Validation epoch 3: 263250it [33:37, 130.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.846343779677113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4: 100%|██████████| 9255/9255 [04:57<00:00, 31.16it/s, loss=0.0765]\n",
            "Validation epoch 4: 263250it [33:47, 129.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9031225071225071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5: 100%|██████████| 9255/9255 [04:51<00:00, 31.76it/s, loss=0.0656]\n",
            "Validation epoch 5: 263250it [31:49, 137.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9299259259259259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "i = 0\n",
        "for epoch in range(1, epochs+1):\n",
        "    # The process bar\n",
        "    bar = tqdm(dl_train, desc=f\"Train epoch {epoch}\")\n",
        "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
        "        # Write your code here\n",
        "        # Clear the gradient\n",
        "\n",
        "        batch_x = batch_x.to(device, non_blocking=True)\n",
        "        batch_y = batch_y.to(device, non_blocking=True)\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        batch_pred_y = model(batch_x.to(device), batch_x_lens)\n",
        "\n",
        "        # Write your code here\n",
        "        # Input the prediction and ground truths to loss function\n",
        "        # Back propagation\n",
        "\n",
        "        loss = criterion(batch_pred_y.view(-1, vocab_size), batch_y.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_value_(model.parameters(), grad_clip) # gradient clipping\n",
        "\n",
        "        # Write your code here\n",
        "        # Optimize parameters in the model\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "        i+=1\n",
        "        if i%50==0:\n",
        "            bar.set_postfix(loss = loss.item())\n",
        "\n",
        "    # Evaluate your model\n",
        "    matched = 0\n",
        "    total = 0\n",
        "    bar_eval = tqdm(df_eval.iterrows(), desc=f\"Validation epoch {epoch}\")\n",
        "    for _, row in bar_eval:\n",
        "        batch_x = row['src']\n",
        "        batch_y = row['tgt']\n",
        "\n",
        "        # prediction = # An example of using generator: model.generator('1+1=')\n",
        "\n",
        "        # Write your code here. Input the batch_x to the model and generate the predictions\n",
        "        # Write your code here.\n",
        "        # Check whether the prediction match the ground truths\n",
        "        # Compute exact match (EM) on the eval dataset\n",
        "        # EM = correct/total\n",
        "\n",
        "        prediction = \"\".join(model.generator(batch_x, max_len=50))\n",
        "        prediction = prediction.split(\"=\")[-1].replace(\"<eos>\", \"\")\n",
        "        is_correct = int(prediction == batch_y)\n",
        "        matched += is_correct\n",
        "        total += 1\n",
        "\n",
        "    print(matched/total)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}