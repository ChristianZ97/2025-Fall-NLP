# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TJfh7zuVToF05SYsgytQtozXTb6xXx4i
"""

#! pip install evaluate
#! pip install datasets==2.21.0
#! pip install git+https://github.com/KellerJordan/Muon

from transformers import GPT2Tokenizer, GPT2Model
from datasets import load_dataset
from evaluate import load
import torch
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from tqdm import tqdm

device = "cuda" if torch.cuda.is_available() else "cpu"
#  You can install and import any other libraries if needed

from muon import SingleDeviceMuon
import time
import numpy as np
import random
import os

os.makedirs("./saved_models", exist_ok=True)


def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    # print(f"\n\nUsing random seed {seed}")


from seed import SEED

set_seed(SEED)

# Some Chinese punctuations will be tokenized as [UNK], so we replace them with English ones
token_replacement = [
    ["：", ":"],
    ["，", ","],
    ["“", '"'],
    ["”", '"'],
    ["？", "?"],
    ["……", "..."],
    ["！", "!"],
]

tokenizer = GPT2Tokenizer.from_pretrained("openai-community/gpt2", cache_dir="./cache/")
tokenizer.pad_token = tokenizer.eos_token


class SemevalDataset(Dataset):
    def __init__(self, split="train") -> None:
        super().__init__()
        assert split in ["train", "validation", "test"]
        self.data = load_dataset(
            "sem_eval_2014_task_1",
            split=split,
            trust_remote_code=True,
            cache_dir="./cache/",
        ).to_list()

    def __getitem__(self, index):
        d = self.data[index]
        # Replace Chinese punctuations with English ones
        for k in ["premise", "hypothesis"]:
            for tok in token_replacement:
                d[k] = d[k].replace(tok[0], tok[1])
        return d

    def __len__(self):
        return len(self.data)


# data_sample = SemevalDataset(split="train").data[:3]
# print(f"Dataset example: \n{data_sample[0]} \n{data_sample[1]} \n{data_sample[2]}")

# Define the hyperparameters
# You can modify these values if needed

muon_lr = 0.000570946127776095
muon_weight_decay = 0.0330037215159045
adamw_lr = 0.000144505377143309
adamw_weight_decay = 0.0352225102350684
dropout_rate = 0.05

epochs = 3
train_batch_size = 32
validation_batch_size = 256

# TODO1: Create batched data for DataLoader
# `collate_fn` is a function that defines how the data batch should be packed.
# This function will be called in the DataLoader to pack the data batch.


def collate_fn(batch):
    # TODO1-1: Implement the collate_fn function
    # Write your code here
    # The input parameter is a data batch (tuple), and this function packs it into tensors.
    # Use tokenizer to pack tokenize and pack the data and its corresponding labels.
    # Return the data batch and labels for each sub-task.

    pair_ids = [item["sentence_pair_id"] for item in batch]
    premises = [item["premise"] for item in batch]
    hypotheses = [item["hypothesis"] for item in batch]
    relatedness_labels = [item["relatedness_score"] for item in batch]
    entailment_labels = [item["entailment_judgment"] for item in batch]

    encoded = tokenizer(
        premises,
        hypotheses,
        padding=True,
        truncation=True,
        max_length=512,
        return_tensors="pt",
    )

    relatedness_tensor = torch.tensor(relatedness_labels, dtype=torch.float)
    entailment_tensor = torch.tensor(entailment_labels, dtype=torch.long)

    return {
        "sentence_pair_id": pair_ids,
        "input_ids": encoded["input_ids"],
        "attention_mask": encoded["attention_mask"],
        # "token_type_ids": encoded["token_type_ids"],
        "relatedness_score": relatedness_tensor,
        "entailment_judgment": entailment_tensor,
    }


# TODO1-2: Define your DataLoader
# dl_train = # Write your code here
# dl_validation = # Write your code here
# dl_test = # Write your code here

dl_train = DataLoader(
    SemevalDataset(split="train"),
    batch_size=train_batch_size,
    shuffle=True,
    collate_fn=collate_fn,
    num_workers=min(4, os.cpu_count()),
    pin_memory=True,
    persistent_workers=True,
)
dl_validation = DataLoader(
    SemevalDataset(split="validation"),
    batch_size=validation_batch_size,
    shuffle=False,
    collate_fn=collate_fn,
    num_workers=min(4, os.cpu_count()),
    persistent_workers=True,
)
dl_test = DataLoader(
    SemevalDataset(split="test"),
    batch_size=validation_batch_size,
    shuffle=False,
    collate_fn=collate_fn,
    num_workers=min(4, os.cpu_count()),
    persistent_workers=True,
)


# TODO2: Construct your model
class MultiLabelModel(torch.nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Write your code here
        # Define what modules you will use in the model
        # Please use "google-bert/bert-base-uncased" model (https://huggingface.co/google-bert/bert-base-uncased)
        # Besides the base model, you may design additional architectures by incorporating linear layers, activation functions, or other neural components.
        # Remark: The use of any additional pretrained language models is not permitted.

        self.gpt2 = GPT2Model.from_pretrained(
            "openai-community/gpt2", cache_dir="./cache/"
        )
        self.gpt2.config.pad_token_id = tokenizer.eos_token_id
        hidden_size = self.gpt2.config.hidden_size

        self.shared_dense = torch.nn.Sequential(
            torch.nn.Linear(hidden_size, hidden_size),
            torch.nn.ReLU(),
            torch.nn.Dropout(dropout_rate),
        )

        self.regression_head = torch.nn.Sequential(
            torch.nn.Linear(hidden_size, 256),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.1),
            torch.nn.Linear(256, 1),  # [1, 5]
            torch.nn.Tanh(),
        )

        self.classification_head = torch.nn.Sequential(
            torch.nn.Linear(hidden_size, 256),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.1),
            torch.nn.Linear(256, 3),  # 0, 1, 2
        )

    def forward(self, **kwargs):
        # Write your code here
        # Forward pass

        input_ids = kwargs["input_ids"]
        attention_mask = kwargs["attention_mask"]
        # token_type_ids = kwargs["token_type_ids"]

        gpt2_output = self.gpt2(
            input_ids=input_ids,
            attention_mask=attention_mask,
            # token_type_ids=token_type_ids,
        )

        last_token_representation = gpt2_output.last_hidden_state[
            torch.arange(input_ids.shape[0]), attention_mask.sum(dim=1) - 1
        ]
        shared_features = self.shared_dense(last_token_representation)
        regression_output = (
            self.regression_head(shared_features) + 1
        ) * 2.5  # [-1, 1] -> [0, 5], actual data is [1, 5]
        classification_output = self.classification_head(shared_features)

        return {
            "relatedness_score": regression_output,
            "entailment_judgment": classification_output,
        }


# TODO3: Define your optimizer and loss function

model = MultiLabelModel().to(device)
# TODO3-1: Define your Optimizer
# optimizer = # Write your code here

muon_params = [
    p
    for layer in [
        model.gpt2,
        model.shared_dense,
        model.regression_head,
        model.classification_head,
    ]
    for p in layer.parameters()
    if p.ndim >= 2
]

adamw_params = [
    p
    for layer in [
        model.gpt2,
        model.shared_dense,
        model.regression_head,
        model.classification_head,
    ]
    for p in layer.parameters()
    if p.ndim < 2
]

optimizer = [
    SingleDeviceMuon(muon_params, lr=muon_lr, weight_decay=muon_weight_decay),
    torch.optim.AdamW(adamw_params, lr=adamw_lr, weight_decay=adamw_weight_decay),
]


# TODO3-2: Define your loss functions (you should have two)
# Write your code here

criterion_regression = torch.nn.MSELoss()
criterion_classification = torch.nn.CrossEntropyLoss()

# scoring functions
psr = load("pearsonr")
acc = load("accuracy")

best_score = 0.0
for ep in range(epochs):
    pbar = tqdm(dl_train)
    pbar.set_description(f"Training epoch [{ep+1}/{epochs}]")
    model.train()
    # TODO4: Write the training loop
    # Write your code here
    # train your model
    # clear gradient
    # forward pass
    # compute loss
    # back-propagation
    # model optimization

    for batch in pbar:
        batch = {
            k: v.to(device, non_blocking=True) if isinstance(v, torch.Tensor) else v
            for k, v in batch.items()
        }
        optimizer[0].zero_grad()
        optimizer[1].zero_grad()

        outputs = model(**batch)

        loss_reg = criterion_regression(
            outputs["relatedness_score"].squeeze(), batch["relatedness_score"]
        )
        loss_clf = criterion_classification(
            outputs["entailment_judgment"], batch["entailment_judgment"]
        )
        loss = 0.5 * loss_reg + 0.5 * loss_clf

        loss.backward()

        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        optimizer[0].step()
        optimizer[1].step()

        pbar.set_postfix(loss=loss.item())

    pbar = tqdm(dl_validation)
    pbar.set_description(f"Validation epoch [{ep+1}/{epochs}]")
    model.eval()
    # TODO5: Write the evaluation loop
    # Write your code here
    # Evaluate your model
    # Output all the evaluation scores (PearsonCorr, Accuracy)
    # pearson_corr = # Write your code here
    # accuracy = # Write your code here
    # print(f"F1 Score: {f1.compute()}")

    with torch.no_grad():
        pearson_corr = 0
        accuracy = 0
        all_reg_preds = []
        all_reg_targets = []
        all_clf_preds = []
        all_clf_targets = []

        for batch in pbar:
            batch = {
                k: v.to(device, non_blocking=True) if isinstance(v, torch.Tensor) else v
                for k, v in batch.items()
            }
            outputs = model(**batch)

            reg_pred = outputs["relatedness_score"].squeeze().cpu().numpy()
            reg_target = batch["relatedness_score"].cpu().numpy()
            all_reg_preds.extend(reg_pred)
            all_reg_targets.extend(reg_target)

            clf_pred = torch.argmax(outputs["entailment_judgment"], dim=1).cpu().numpy()
            clf_target = batch["entailment_judgment"].cpu().numpy()
            all_clf_preds.extend(clf_pred)
            all_clf_targets.extend(clf_target)

        pearson_result = psr.compute(
            predictions=all_reg_preds, references=all_reg_targets
        )
        pearson_corr = pearson_result["pearsonr"]

        accuracy_result = acc.compute(
            predictions=all_clf_preds, references=all_clf_targets
        )
        accuracy = accuracy_result["accuracy"]

        combined_score = 0.5 * pearson_corr + 0.5 * accuracy
        print(
            f"Epoch {ep+1}: Pearson={pearson_corr:.4f}, Accuracy={accuracy:.4f}, Combine={combined_score:.4f}"
        )

        if combined_score > best_score:
            best_score = combined_score
            torch.save(model.state_dict(), f"./saved_models/best_model.ckpt")

# Load the model
model = MultiLabelModel().to(device)
model.load_state_dict(torch.load(f"./saved_models/best_model.ckpt", weights_only=True))

# Test Loop
pbar = tqdm(dl_test, desc="Test")
model.eval()

# TODO6: Write the test loop
# Write your code here
# We have loaded the best model with the highest evaluation score for you
# Please implement the test loop to evaluate the model on the test dataset
# We will have 10% of the total score for the test accuracy and pearson correlation

with torch.no_grad():
    pearson_corr = 0
    accuracy = 0
    all_reg_preds = []
    all_reg_targets = []
    all_clf_preds = []
    all_clf_targets = []

    for batch in pbar:
        batch = {
            k: v.to(device, non_blocking=True) if isinstance(v, torch.Tensor) else v
            for k, v in batch.items()
        }
        outputs = model(**batch)

        reg_pred = outputs["relatedness_score"].squeeze().cpu().numpy()
        reg_target = batch["relatedness_score"].cpu().numpy()
        all_reg_preds.extend(reg_pred)
        all_reg_targets.extend(reg_target)

        clf_pred = torch.argmax(outputs["entailment_judgment"], dim=1).cpu().numpy()
        clf_target = batch["entailment_judgment"].cpu().numpy()
        all_clf_preds.extend(clf_pred)
        all_clf_targets.extend(clf_target)

        batch_size = batch["input_ids"].shape[0]
        pair_ids = batch["sentence_pair_id"]

    pearson_result = psr.compute(predictions=all_reg_preds, references=all_reg_targets)
    pearson_corr = pearson_result["pearsonr"]

    accuracy_result = acc.compute(predictions=all_clf_preds, references=all_clf_targets)
    accuracy = accuracy_result["accuracy"]

    combined_score = 0.5 * pearson_corr + 0.5 * accuracy
    print(
        f"\nTest: Pearson={pearson_corr}, Accuracy={accuracy}, Combine={combined_score}"
    )
