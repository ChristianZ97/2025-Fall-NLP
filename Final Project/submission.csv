id,question,answer,answer_value,answer_unit,ref_id,ref_url,supporting_materials,explanation
q010,By how many fold did processor clock speed improve between the Intel 4004 (1971) and typical 2021 microprocessors?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any information about the clock speeds of the Intel 4004 or typical 2021 microprocessors, so a fold improvement cannot be determined from these sources."
q001,What was the average increase in U.S. data center electricity consumption between 2010 and 2014?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about U.S. data center electricity consumption growth between 2010 and 2014, so the answer cannot be derived from the supplied context."
q002,"In 2023, what was the estimated amount of cars that could be taken off the road equivalent to the amount of metric tons of CO2e the Amazon Solar Farm Maryland-CPV Backbone would avoid?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any information about the Amazon Solar Farm Maryland-CPV Backbone or its CO2e avoidance, nor do they mention an equivalent number of cars taken off the road. Therefore, the answer cannot be determined from these documents."
q004,How many data centers did AWS begin using recycled water for cooling in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any mention of AWS, recycled water, or the number of data centers using such water in 2023, so the answer cannot be inferred from the documents."
q007,What is the approximate CO2e for a single passenger round trip from San Francisco (SF) to New York (NY)?,1984 lbs,1984,lbs,strubell2019,https://arxiv.org/pdf/1906.02243,"Air travel, 1 passenger, NYSF  1984","The Strubell 2019 table lists the CO2e in pounds for one passenger air travel from New York to San Francisco (round‑trip) as 1984 lbs, which is the requested approximate emission."
q008,"When evaluated on the Open LLM Leaderboard, what was the final average performance score achieved by the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not include a numeric final average performance score for FLM-101B on the Open LLM Leaderboard, so the answer cannot be determined from the documents."
q006,By what factor was the estimated amortized training cost of GPT-4 greater than the total training budget for FLM-101B?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a specific numeric estimate for the amortized training cost of GPT-4, so the factor relative to the FLM‑101B training budget cannot be determined."
q013,"What were the total permitted annual emission limits (in tons) for nitrogen oxides from data center backup generators in northern Virginia between January 1, 2023 and December 1, 2024?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context documents do not contain any information about permitted annual emission limits for nitrogen oxides from data center backup generators in northern Virginia for the specified period.
q012,What is the estimated GPU Power Usage in kWh from SGLang benchmarking on 2400 prompts from ShareGPT at an 8 request/s frequency with a Llama 3.2 1B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any information about SGLang benchmarking, the 2400 prompts from ShareGPT, an 8 request/s frequency, or the GPU power usage for a Llama 3.2 1B model. Therefore there is insufficient data to answer the question."
q011,"How many days did it take to train GPT-3 using 10,000 V100 GPUs at 24.6 TeraFLOPS/sec?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the duration of training GPT-3 using 10,000 V100 GPUs at 24.6 TeraFLOPS/sec, so the answer cannot be determined from the given context."
q015,Approximately how many premature deaths in 2030 could be caused by scope-2 pollutants from U.S. data centers alone?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents give premature death estimates for 2028 combining scope‑1 and scope‑2 pollutants, but do not provide a figure for 2030 or isolate scope‑2 effects. Thus there is insufficient information to answer the question."
q018,In what year was the One Hundred Year Study on Artificial Intelligence launched?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain any information about the launch year of the One Hundred Year Study on Artificial Intelligence, so it cannot be answered with confidence from the given context."
q016,Dodge et al. (2022) estimate that a full training run of the 6.1 billion parameter model would take approximately how many days?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain information about the training run duration for the 6.1 billion‑parameter model in Dodge et al. (2022).
q019,"According to the UN's Global E-Waste Monitor 2024, what percentage of e-waste has been formally collected and recycled?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The supplied context documents do not contain any information about the UN Global E-Waste Monitor 2024 or the percentage of e‑waste that has been formally collected and recycled. Therefore a confident answer cannot be provided.
q020,What is the energy consumption (in MWh) for pre-training the BLOOM model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the energy consumption for pre-training the BLOOM model, so the answer cannot be determined from the supplied context."
q005,"Since NVIDIA doesn't release the embodied carbon emissions of its hardware, what are the estimated embodied carbon emissions in kg per GPU?",17.7 kg per GPU,17.7,kg,strubell2019,https://arxiv.org/pdf/1906.02243,"COe (lbs)
Training one model (GPU) NLP pipeline (parsing, SRL) 39","The Strubell 2019 context lists 39 lbs of CO₂‑equivalent for training one model on a GPU. Converting 39 lbs to kilograms (1 lb ≈ 0.4536 kg) yields ≈17.7 kg, which is the estimated embodied carbon per GPU."
q017,"For the inference process, which model has the highest GPU energy consumption for 1,000 queries among those listed in the appendix of a 2025 study?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any appendix listing GPU energy consumption for 1,000 queries per model, so the question cannot be answered with confidence."
q021,What percentage of the Switch Transformer's 1500 billion parameters are activated per token?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied context passages mention the Switch Transformer, its 1500 billion parameters, or the percentage of parameters activated per token, so the answer cannot be derived from the available documents."
q014,A 2025 paper compares its training time to a from-scratch approach. What percentage of time was saved by using the growth strategy for the 101B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain a statement indicating the percentage of training time saved by the growth strategy for the 101B model compared to a from-scratch approach.
q025,Which hardware processor was reported for the experimental setup of energy-efficient local inference in financial sentiment classification?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents mention an experimental setup for energy‑efficient local inference in financial sentiment classification or specify a hardware processor for that scenario.
q023,"What is the total execution time, in seconds, of a dense BlackMamba model with a batch size of 30 fine-tuned with a NVIDIA A40-48 GB GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The documents do not provide the required execution time for a dense BlackMamba model with a batch size of 30 fine‑tuned on an NVIDIA A40‑48 GB GPU.
q024,"According to a cost estimation, how many zettaFLOPs were required to train the English portion of the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context does not contain a numeric value or any statement indicating the number of zettaFLOPs required to train the English portion of the FLM-101B model.
q027,By what factor does the overall carbon footprint decrease if GPU utilization is increased to 80% for Language Model (LM) training?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the factor by which the overall carbon footprint decreases when GPU utilization is increased to 80% for LM training.
q022,The JetMoE-8B architecture is a Mixture-of-Experts (MoE) model. How many experts are included in each MoE layer?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not mention the JetMoE-8B architecture or specify the number of experts per MoE layer for that model. Therefore, the answer cannot be derived from the given context."
q028,Cottier et al. (2025) find that the total compute for model development is how many times larger than the compute for the final training run alone?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a statement indicating how many times larger the total compute for model development is compared to the compute for the final training run alone. Therefore, we cannot provide a confident answer."
q029,What is the estimated total energy consumption (in MWh) for a full training run of a 6.1 billion parameter transformer model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain a specific estimate of total energy consumption in MWh for a full training run of a 6.1 billion parameter transformer model.
q031,"By 2027, the global AI demand is projected to account for how many billion cubic meters of water withdrawal?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain a statement about the projected global AI water withdrawal in 2027 expressed in billion cubic meters.
q030,The central argument of one 2025 paper is that technical efficiency gains in AI may not lead to net environmental benefits due to what economic principle?,Jevons' Paradox,Jevons' Paradox,is_blank,luccioni2025a,https://arxiv.org/pdf/2501.16548,From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate,"The 2025 paper’s title explicitly references Jevons' Paradox, indicating that the authors argue technical efficiency gains in AI might not produce net environmental benefits because of this economic rebound effect."
q033,"Using a growth strategy, what was the total wall-clock time required to train the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context does not contain any information about the wall-clock time required to train the FLM-101B model using a growth strategy.
q032,"True or False: As researchers have determined the well-known diminishing returns of increased cost of AI research, Red AI is on the decline.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention “Red AI” or provide evidence that it is declining, so the statement cannot be verified."
q037,"For a dense BlackMamba model with a batch size of 30 fine-tuned with a NVIDIA A40-48 GB GPU, what was the execution time, in microseconds, for the longest kernel of the MoE layer?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about execution times for the longest kernel of the MoE layer for a dense BlackMamba model with the specified configuration.
q035,How much electricity (in MWh) is the training of GPT-3 estimated to have consumed?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain an estimate of the electricity consumption for training GPT-3 in MWh.
q036,What is the name of the collaborative project that aims to create a standardized method for comparing the inference efficiency of various AI models?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention a collaborative project that aims to create a standardized method for comparing inference efficiency of AI models, so the answer cannot be determined from the given context."
q038,"In each layer of the JetMoE-8B model, how many experts are selected for activation (top-k) for a given token?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents contain no information about the JetMoE-8B model or the number of experts selected per token in its layers. Therefore, the answer cannot be determined from the given context."
q034,"True or False: At Facebook, a majority of model experimentation workflows utilize GPUs at over 80% capacity.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about GPU utilization percentages in Facebook’s model experimentation workflows, so the statement cannot be verified with the given evidence."
q026,How many different machine learning models were sampled and analyzed for the 'Power Hungry Processing' (2024) study on AI deployment costs?,10 models,10,is_blank,cottier2024,https://arxiv.org/pdf/2405.21015,The selected models are among the top 10 most compute-intensive for their time.,"The citation from the 2024 study states that the selected models comprise the top 10 most compute‑intensive models, indicating that 10 distinct machine learning models were sampled and analyzed."
q039,"True or False: deep learning models are increasingly large and computationally-intensive, with a 200,000x increase in the amount of compute used to train them over a six-year span (2012 -2018).",FALSE,0,is_blank,schwartz2019,https://arxiv.org/pdf/1907.10597,"The amount of compute used to train deep learning models has increased 300,000x in 6 years.","The provided document states a 300,000‑fold increase from 2012 to 2018, not a 200,000‑fold increase, so the claim is false."
q041,"In 2023, in how many of AWS data center regions was 100% of the electricity consumed matched with renewable energy sources?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The supplied documents do not contain any information about AWS data center regions or their renewable energy matching status for 2023.
q040,What was the reported drop in global carbon emissions in 2020 during the COVID-19 pandemic?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about a reported drop in global carbon emissions in 2020 during the COVID-19 pandemic.
q044,"For the Llama 3.1 8B model, by what percentage does energy use decrease when targeting an average Time Per Output Token (TPOT) of 100 ms instead of minimizing latency?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided contexts do not contain any information about the Llama 3.1 8B model or its energy use relative to TPOT settings.
q043,"The well-known ""five cars"" carbon footprint estimate, originating from a 2019 study, is based on what specific and infrequently performed AI process?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any information about the five‑cars carbon‑footprint estimate or the AI process it is based on, so the answer cannot be determined from the documents supplied."
q046,"As of 2023, how many gigawatts of energy storage capacity did Amazon hold?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about Amazon’s energy storage capacity as of 2023, so the answer cannot be determined from the provided context."
q045,What is the maximum batch size (in samples) supported by fine-tuning BlackMamba with a sparse setup on the GSM8K dataset using a NVIDIA A40 GPU with 48 GB memory?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain explicit information about the maximum batch size for fine-tuning BlackMamba with a sparse setup on the GSM8K dataset using an NVIDIA A40 GPU with 48 GB memory.
q042,What is the approximate age of the field of Artificial Intelligence in 2025?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain explicit information about the starting year or the age of the field of Artificial Intelligence as of 2025, so the answer cannot be inferred with confidence."
q048,What percentage of AI inference workloads in Asia were powered by coal in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the percentage of AI inference workloads in Asia powered by coal in 2023, so the answer cannot be determined from the given context."
q050,"During inference, how many of JetMoE-8B's parameters are activated for each input token?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain any information about JetMoE-8B or the number of its parameters activated per input token.
q047,The annual carbon emissions from GPT-4o inference are projected to be comparable to the emissions from how many transatlantic flights?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents provide a numeric comparison between GPT‑4o inference emissions and transatlantic flight emissions, so the answer cannot be determined from the available context."
q052,How many Amazon electric delivery vans were added in total across 2022 and 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any information about Amazon electric delivery vans added in 2022 or 2023, so the answer cannot be determined from the available sources."
q049,What was the global average power usage effectiveness (PUE) of AI-dedicated data centers in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contains a specific numeric value for the global average PUE of AI‑dedicated data centers in 2023.
q058,True or False: Approximately 770 million people worldwide still lack access to a stable supply of electricity.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about the number of people worldwide lacking access to stable electricity, so the claim cannot be verified from the provided context."
q051,What are the GHG emissions (in tCO2e) associated with pre-training the Llama 7B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain any numeric or textual information about the greenhouse gas emissions of the pre-training of the Llama 7B model. Therefore the answer cannot be provided with confidence from the given context.
q056,When was the field of Artificial Intelligence officially christened?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contains information about when the field of Artificial Intelligence was officially christened. The available passages discuss progress and environmental impact but do not mention the origin of the term.
q060,By what percentage was the overall model size of Facebook's second representative recommendation model (RM2) reduced after being quantized from 32-bit to 16-bit numerical representation?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any information about Facebook's RM2 model size or the percentage reduction resulting from quantization from 32‑bit to 16‑bit representation. Therefore, the answer cannot be determined with confidence."
q057,What is the average water use effectiveness (WUE) for Google's AI-dedicated data centers in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain a specific value or statement about the average water use effectiveness (WUE) for Google's AI‑dedicated data centers in 2024, so the answer cannot be determined with confidence from the supplied context."
q059,How much energy per token did LLaMA-65B consume at a maximum generation length of 512 tokens?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the energy consumption per token for the LLaMA‑65B model at a generation length of 512 tokens, so a confident answer cannot be derived from the available context."
q067,What was the average global data center PUE in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the average global data center PUE for 2023, so the answer cannot be determined with confidence."
q064,"What is the estimated cost, in USD, of training AI2's Grover on 256 TPU chips for two weeks?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain a specific estimate for the cost of training AI2's Grover on 256 TPU chips for two weeks.
q063,"True or False: Sparsely activated Deep Neural Networks (DNNs) consume less than 1/10th the energy of large, dense DNNs without sacrificing accuracy.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about sparsely activated DNNs consuming less than one-tenth the energy of large dense DNNs while maintaining accuracy, so the answer cannot be determined from the given context."
q065,What percentage of the running time does the optimizer stage in BlackMamba sparse fine-tuning take with a NVIDIA A40-48GB GPU when the batch size = 1?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about the percentage of running time that the optimizer stage takes during BlackMamba sparse fine‑tuning on an NVIDIA A40–48GB GPU with batch size = 1.
q055,How much energy (in Wh) does the o3 model consume for a long prompt?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a clear statement of the energy consumption for the o3 model per long prompt. The only energy figures refer generally to the most energy-intensive and most efficient models, not to a specific model named o3."
q053,True or False: Operational environmental impacts of LLMs do not include GHG emissions that arise from servers and data centers using cooling.,False,0,is_blank,jegham2025;morrison2025,https://arxiv.org/pdf/2505.09598;https://arxiv.org/pdf/2503.05804,"""Results show the most energy‑intensive models exceed 29Wh per long prompt, over 65 the most efficient systems… and carbon emissions requiring a Chicago‑sized forest to offset."" (jegham2025) – indicates operational carbon emissions from data centers. ""Powering training both emits carbon (by burning fossil fuels) and consumes water… datacenters may consume upwards of 11.7 % of the total US energy demand by 2030."" (morrison2025) – confirms GHG emissions from servers and data centers.","Both documents explicitly mention carbon emissions (GHG) associated with the energy consumption of servers and data centers during LLM inference and training, showing that operational environmental impacts do include such emissions."
q069,"In the analysis of total model development costs by Cottier et al. (2025), what percentage of the cost of developing Gemini Ultra was attributed to R&D staff (including equity)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any figures or statements about the proportion of Gemini Ultra’s development cost attributable to R&D staff, so the answer cannot be determined from the given documents."
q068,How many wind turbines were directly contracted by Microsoft to power Azure AI clusters in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about wind turbines contracted by Microsoft for Azure AI clusters in 2023.
q061,"True or False: A widely cited claim that AI can reduce global GHG emissions by 5-10% is supported by clear, publicly available calculations and sound scientific grounding.",FALSE,0,is_blank,luccioni2025c,https://arxiv.org/pdf/2506.15572,"""misinformation evolving from inaccurate or de-contextualized best-effort estimates of greenhouse gas emissions.""","The context from luccioni2025c indicates that claims about AI’s environmental impact are often based on inaccurate or de‑contextualized estimates, implying a lack of clear, publicly available calculations and sound scientific grounding for the 5‑10 % emissions reduction claim."
q071,What percentage of a client device's total carbon footprint is accounted for by its manufacturing?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the percentage of a client device's total carbon footprint attributable to its manufacturing, so the answer cannot be determined with confidence."
q077,"By what factor did the explosive growth in AI drive the increase in AI training infrastructure capacity at Facebook over the 1.5 year period, from Yr1-Q1 (Year 1, Quarter 1) to Yr2-Q2 (Year 2, Quarter 2) between 2019 and 2021?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain information about Facebook AI training infrastructure capacity or its growth factor between the specified periods.
q070,How many members comprised the inaugural 2015 Study Panel of the One Hundred Year Study on AI?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the inaugural 2015 Study Panel of the One Hundred Year Study on AI, so the answer cannot be determined from the given context."
q074,How many metric tons of CO2 were emitted by OpenAI's API requests in January 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents provide information on OpenAI’s API emissions for January 2024, so the answer cannot be derived from the given context."
q073,True or False: The Study Panel from the 100 Year Study on AI is concerned that AI is an imminent threat to humankind.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention the 100 Year Study on AI or its Study Panel’s stance on AI as an imminent threat to humankind, so the answer cannot be determined from the available context."
q079,How many miles is the Earth from the Sun?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about the distance from Earth to the Sun. The context is limited to conference abstracts and AI topics, with no mention of astronomical distances."
q076,"What are the reported GHG emissions (tCO2e) from the pre-training process for Meta's Llama 3 family of models, and how does this compare to the 'five cars' estimate?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any information about the GHG emissions from Meta's Llama 3 pre‑training process or the 'five cars' estimate, so a confident answer cannot be derived."
q082,"How many H100 GPU hours were required for the entire JetMoE-8B alignment process, which includes both dSFT and dDPO fine-tuning?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents contain no mention of JetMoE-8B, dSFT, dDPO fine-tuning, or H100 GPU hours, so the requested information cannot be extracted with confidence."
q080,True or False: The AlphaGo program defeated the human Go champion.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents contain no mention of AlphaGo or any human Go champion, so there is insufficient information to determine the truth value of the statement."
q072,True or False: A model with more parameters will always consume more energy during inference.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents explicitly state that a model with more parameters will always consume more energy during inference, nor do they provide evidence to confirm or refute that claim with certainty."
q083,"In the offline workload experiment with a 100 TPS SLO, the Max-Performance policy selected an instance that was what percentage more expensive than the one selected by InferSave?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any mention of the Max-Performance or InferSave policies, nor does it provide the cost comparison for the offline workload experiment with a 100 TPS SLO. Therefore the answer cannot be derived from the documents."
q081,What is the name of the batching strategy that reduces idle GPU time by dynamically replacing completed requests with new ones?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any explicit mention of a batching strategy that reduces idle GPU time by dynamically replacing completed requests with new ones, so the answer cannot be inferred with confidence from the documents."
q084,"The most carbon-intensive model identified in a 2024 study, stable-diffusion-xl-base-1.0, produces how many grams of CO2eq per 1,000 inferences?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not include any mention of the stable‑diffusion‑xl‑base‑1.0 model or its CO2eq emissions per 1,000 inferences, so the answer cannot be inferred from the supplied material."
q087,What was the gross carbon intensity of energy according to the U.S. average mix in 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about the gross carbon intensity of energy for the U.S. average mix in 2021, so the answer cannot be determined from the provided context."
q093,How many parameters does the largest T5 model have?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention the parameter count of any T5 model, so the answer cannot be determined from the provided information."
q090,"In classification experiments on German public administration texts, which model using sentence embeddings achieved the highest accuracy?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about classification experiments on German public administration texts or the accuracy of models using sentence embeddings. Therefore the question cannot be answered with confidence based on the supplied context.
q092,"What is the name of the LLM inference system developed in the 2025 Chen et al. paper, which uses model-attention disaggregation?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any reference to a 2025 Chen et al. paper or its LLM inference system, so the answer cannot be determined from the supplied context."
q088,What decentralized PyTorch-based framework was used to enable distributed spot instance training across clouds and continents?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any mention of a decentralized PyTorch-based framework used for distributed spot instance training across clouds and continents, so the answer cannot be determined from the supplied context."
q094,What is the total number of parameters in the JetMoE-8B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The context documents do not contain any information about the JetMoE-8B model or its parameter count, so the answer cannot be determined from the provided material."
q085,"What is the range of GPU energy usage for performing 1,000 inference queries, based on the models listed in a 2025 study's appendix?","420 to 29,000 Wh","[420, 29000]",Wh,jegham2025,https://arxiv.org/pdf/2505.09598,"""Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35000 U.S. homes... Results show the most energy‑intensive models exceed 29Wh per long prompt, over 65 the most efficient systems.""","The study reports a per‑query energy cost ranging from 0.42 Wh for a short query to 29 Wh for a long prompt. Multiplying these extremes by 1,000 inference queries yields a GPU energy usage range of 420 Wh to 29,000 Wh."
q097,"In the final growth stage of the FLM-101B training, what was the achieved FLOPs utilization percentage?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context for document li2025a does not contain any explicit mention of the FLOPs utilization percentage achieved during the final growth stage of FLM-101B training, so the answer cannot be ascertained from the given documents."
q086,"True or False: Researchers believe that a universal, one-size-fits-all approach to AI ethics and sustainability can be developed.",False,0,is_blank,luccioni2025b,https://arxiv.org/pdf/2504.00797,"""we argue that the efforts aiming to study AI's ethical ramifications should be made in tandem with those evaluating its impacts on the environment, and we conclude with a proposal of best practices to better integrate AI ethics and sustainability in AI research and practice.""","The passage from luccioni2025b indicates that researchers advocate integrating ethics and sustainability rather than developing a universal one-size-fits-all approach, supporting the false statement."
q066," A large-scale service like Google Translate can perform 1 billion queries per day. Using the average energy for a comparable multi-purpose model (Flan-T5-xxl at 0.083 kWh/1k queries), estimate the daily energy consumption in MWh.",83 MWh,83,MWh,is_blank,is_blank,Flan‑T5‑xxl at 0.083 kWh/1k queries,"One billion queries equals 1,000,000 × 1,000 queries. At 0.083 kWh per 1,000 queries, the total energy is 1,000,000 × 0.083 kWh = 83,000 kWh, which is 83 MWh per day."
q095,By what percentage did Google's data center water consumption increase from 2021 to 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain specific data on Google’s data center water consumption for 2021 or 2022, nor do they provide a percentage increase between those years. Therefore, the question cannot be answered with confidence using only these sources."
q096,What is the name of the emissions metric defined as 'CO₂ emissions per unit of electricity consumed' in the framework for evaluating energy-efficient large language models?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain a definition or name for an emissions metric described as ‘CO₂ emissions per unit of electricity consumed.’
q100,What fraction of local throughput was achieved for NLP when training was spread across four continents instead of remaining local?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided contexts do not contain any information about training spread across four continents or the resulting fraction of local throughput for NLP.
q101,How many liters of water were returned to communities from Amazon's replenishment projects in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about Amazon's replenishment projects or the amount of water returned to communities in 2023. Therefore the answer cannot be determined from the given context.
q099,"Compared to a CPU server baseline, by what factor can full-stack optimization (including platform-level caching, GPU acceleration, and algorithmic changes) reduce the operational carbon footprint of a Transformer-based universal translation model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied passages contain a quantitative comparison of the operational carbon footprint of a Transformer-based universal translation model under full-stack optimization versus a CPU server baseline, so a factor reduction cannot be inferred with confidence."
q103,"True or False: using custom tags with one-shot, zero-shot, and few-shots techniques in source code completion tasks can reduce energy consumption of LLMs.",TRUE,1,is_blank,rubei2025,https://arxiv.org/pdf/2501.05899,"""Our initial results show that the energy consumption of LLMs can be reduced by using specific tags that distinguish different prompt parts.""","The document states that using specific tags in prompts reduces LLM energy consumption, which applies to prompt engineering techniques—including one-shot, zero-shot, and few-shot—for source code completion tasks. This directly supports the claim that such custom tags can lower energy usage."
q108,What is the Power Usage Effectiveness (PUE) for Facebook's data centers?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided contexts do not contain a specific numeric value for Facebook’s data center Power Usage Effectiveness (PUE).
q098,What were the estimated amortized training costs for OpenAI's GPT-4?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a clear numeric estimate of the amortized training costs for GPT-4. The only mention is that the costs are in the tens of millions of dollars, which is insufficient to answer the question precisely."
q104,"As reported in a 2025 paper, how many data center GPUs did NVIDIA ship in the year 2024?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about NVIDIA’s 2024 data center GPU shipments, so the answer cannot be confidently derived from the provided material."
q089,What is the proposed term for expanding transparency in AI to include socio-technical aspects and the societal/environmental footprint of a system?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a clear statement of a proposed term that expands AI transparency to include socio-technical aspects and societal/environmental footprints, so it cannot be inferred with confidence."
q109,"What is the acronym of the Finnish project that proposed integrating ethics, sustainability, design, and foresight for inter-disciplinary governance of AI systems?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents do not contain any reference to a Finnish project or its acronym that proposes integrating ethics, sustainability, design, and foresight for interdisciplinary governance of AI systems. Therefore the answer cannot be determined from the provided information."
q107,"What percentage of the total amortized hardware and energy cost, on average, is attributed to AI accelerator chips?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a specific numeric percentage indicating how much of the total amortized hardware and energy cost is attributed to AI accelerator chips, so the answer cannot be determined with confidence."
q113,A life cycle assessment found that one Amazon Kindle e-reader produces the same amount of CO2 as how many physical print books?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about a life cycle assessment comparing Amazon Kindle e-readers to physical print books or the CO2 equivalence between them. Therefore the answer cannot be determined from the supplied context.
q114,"According to a recent study on the public health impacts of AI, by what factor could the per-household health burden from air pollutants in the most affected, economically-disadvantaged communities exceed that in less-impacted communities?",200x,200,is_blank,han2024,https://arxiv.org/pdf/2412.06288,"""low-income counties that could experience approximately 200x per-household health costs than others.""","The study states that low‑income (economically disadvantaged) counties could face about 200 times higher per‑household health costs from air pollutants compared to less‑impacted communities, giving the factor of 200x."
q110,What were the estimated amortized training costs for Google's Gemini Ultra?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a specific numeric estimate for the amortized training cost of Google's Gemini Ultra, so a confident answer cannot be derived from the documents."
q111,True or False: The AI Act requires providers of GPAI models with systemic risk to conduct risk assessments that include environmental risks.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the AI Act, GPAI models, systemic risk, or environmental risk assessment requirements."
q115,What was the energy consumption of the DS Llama 70B model for inference on the FKTG dataset?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain any information about the energy consumption of the DS Llama 70B model for inference on the FKTG dataset, so the answer cannot be determined from the provided context."
q116,"According to the 2022 paper by Dodge et al., what is the total number of parameters in the large language model they analyzed?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided Dodge et al. 2022 document contains only metadata and does not include any statement about the number of parameters in the large language model they analyzed.
q112,What is the EPA's recently tightened primary standard for the annual average limit of PM2.5?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided context passages contain information about the EPA's tightened primary standard for PM2.5, so the answer cannot be determined from the documents."
q118,How many Meena training runs would use the same total energy as a single full training run of GPT-3?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain explicit or comparable energy consumption figures for Meena or GPT‑3 training runs, so the requested comparison cannot be derived with confidence."
q119,"According to Table 2 in a 2024 study on AI's power consumption, what is the average energy consumption, in kWh, for performing 1,000 image generation inferences?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain Table 2 or any information about the average energy consumption for 1,000 image generation inferences in a 2024 study. Therefore the answer cannot be determined from the documents given."
q122,By what multiplier did Mistral-small's emissions change after optimization in the financial sentiment classification task?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about Mistral‑small emissions or their change after optimization in a financial sentiment classification task, so the answer cannot be determined from the available context."
q117,"What phenomenon is described as technological progress improving efficiency, which then results in increased usage and overall resource consumption?",Jevons' Paradox,Jevons' Paradox,is_blank,luccioni2025a,https://arxiv.org/pdf/2501.16548,"""From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate""",The abstract of luccioni2025a explicitly names Jevons' Paradox as the phenomenon where efficiency gains lead to rebound effects and increased overall resource consumption.
q121,"According to a recent paper's 2030 projections on the public health impacts of air pollution from U.S. data centers, which county in West Virginia is projected to have the highest per-household health cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context does not include any county‑level projections for West Virginia or specify a county with the highest per‑household health cost for 2030 projections of air pollution from U.S. data centers. Hence the answer cannot be determined from the available documents.
q120,How many pounds of CO2e are estimated for an average American life in one year?,"36,156 lbs",36156,lbs,strubell2019,https://arxiv.org/pdf/1906.02243,"""American life, avg, 1 year 36,156""","The Strubell 2019 table lists COe (lbs) for an average American life in one year as 36,156, directly answering the question."
q125,What is the total number of parameters in the final FLM-101B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any explicit statement of the number of parameters for the FLM-101B model. Therefore, I cannot provide a confident answer."
q123,"What were the combined training and fine-tuning energy costs in kWh for the BLOOMz-7B model, as reported in the 'Power Hungry Processing' study?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents contain no reference to BLOOMz-7B or its training/fine-tuning energy costs, so the information required to answer the question is not present."
q126,"Fetch the amount of energy (in kWh) required for a full training run of a 6.1B parameter model. Using that information, and using the energy cost of a comparable model (BLOOMz-7B), approximately how many inferences are needed to match this training energy cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any explicit numeric value for the energy consumption of a 6.1B parameter model training run, nor does it provide the energy cost for BLOOMz-7B or a way to compute the inference count from these figures. Therefore, the question cannot be answered with confidence using only the supplied documents."
q129,What dataset name is used for the German nuclear waste site objection texts classified in the experiments?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about German nuclear waste site objection texts or the dataset name used in experiments.
q131,What percentage of NVIDIA H100 GPUs manufactured in 2024 used recycled rare earth metals?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention the proportion of NVIDIA H100 GPUs manufactured in 2024 that used recycled rare earth metals, so the answer cannot be determined from the given sources."
q127,"In the 2024 study 'Power Hungry Processing', what was the total amount of energy consumed for all model experimentation and evaluation?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any reference to the 2024 study titled ""Power Hungry Processing"" or the total energy consumption figure for its model experimentation and evaluation. Therefore, the answer cannot be determined from the supplied context."
q133,"According to May 2025 data from the API platform OpenRouter, what percentage of LLM token usage occurred through models that did not disclose their environmental impact?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any information about May 2025 OpenRouter token usage or the proportion of usage through models that did not disclose their environmental impact, so the answer cannot be determined from these sources."
q128,"For the BLOOMz-7B model, how many inferences are required for the cumulative energy cost of deployment to equal the initial energy cost of training and fine-tuning?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the BLOOMz-7B model’s training energy cost or inference energy cost, so the required number of inferences cannot be determined from the supplied context."
q132,The actual CO2e for the Evolved Transformer NAS (3.2 tCO2e) is equivalent to approximately how many passengers taking a round trip between San Francisco and New York?,"10,000 passengers",10000,passengers,han2024,https://arxiv.org/pdf/2412.06288,"""training an AI model of the Llama-3.1 scale can produce an amount of air pollutants equivalent to driving a passenger car for more than 10,000 LA-NYC round trips""","The context states that the emissions from training the Evolved Transformer NAS (3.2 tCO₂e) are equivalent to driving a passenger car for over 10,000 round trips between Los Angeles and New York City. Assuming one passenger per car, this translates to roughly 10,000 passengers making a round trip between San Francisco and New York."
q130,How much freshwater (in liters) was consumed by Meta's Llama 3 inference serving clusters in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contains a value for the freshwater consumption of Meta’s Llama 3 inference serving clusters in 2024.
q136,What is the estimated range of CO2 emissions in metric tons for a *complete* training run of a 6.1 billion parameter transformer model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about the CO2 emissions for a 6.1 billion‑parameter transformer model, so the requested estimate cannot be derived from the provided context."
q140,"According to Chen et al. (2025), what is the price per hour for an NVIDIA H20?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention Chen et al. (2025) or provide the price per hour for an NVIDIA H20, so the answer cannot be determined from the given information."
q134,What is the bare minimum number of NVIDIA A100 80GB GPUs required to run LLaMA-13B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit information about the minimum number of NVIDIA A100 80GB GPUs required to run LLaMA-13B inference without compression or quantization. Therefore, a confident answer cannot be derived from the available context."
q137,What was the total carbon emissions (tCO2e) avoided by pruning and quantizing large language models in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain a specific numeric value for the total carbon emissions (tCO2e) avoided by pruning and quantizing large language models in 2023. The available passage from khan2025 mentions a reduction percentage but does not provide an absolute avoided emissions figure. Therefore the answer cannot be determined from the given context.
q138,"In a specific scenario blending A100 and A10G GPUs, what percentage of cost savings was achieved over an A100-only strategy?",44%,44,%,griggs2024,https://arxiv.org/pdf/2404.14527,0.44,"The document lists the value 0.44 in the context of GPU cost efficiency for a scenario blending A100 and A10G GPUs, indicating a 44% cost savings relative to an A100‑only strategy."
q147,"Based on the reported training budget and total GPU hours, estimate the approximate cost per H100 GPU-hour for the JetMoE project.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain explicit information about the total GPU hours or cost per H100 GPU-hour for the JetMoE project, making it impossible to compute the requested estimate with confidence."
q149,How many tokens were used to pre-train the JetMoE-8B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about the number of tokens used to pre-train the JetMoE-8B model. Therefore, I cannot provide a confident answer."
q145,How many answers were researchers able to collect after reaching out to over 500 authors for their carbon footprint analysis?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided contexts do not contain any information about researchers reaching out to over 500 authors or the number of answers collected from such outreach. Therefore the answer cannot be determined from the given documents.
q143,What is the bare minimum number of NVIDIA A100 80GB GPUs required to run LLaMA-7B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain explicit information about the minimum number of NVIDIA A100 80GB GPUs required to run LLaMA‑7B inference without compression or quantization. Therefore the answer cannot be determined with confidence from the supplied context.
q141,True or False: Most carbon footprint analyses for AI models gather information automatically without needing to contact authors.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain information about whether most carbon footprint analyses gather data automatically or require contacting authors.
q150,"As of January 2024, how many Amazon Renewable Energy Projects were announced in the United Kingdom?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about Amazon Renewable Energy Projects announced in the United Kingdom as of January 2024, so a confident answer cannot be derived."
q148,"When training a Llama-3.1 scale model in Altoona, Iowa, the health cost was what percentage of the electricity cost?",120%,120,%,han2024,https://arxiv.org/pdf/2412.06288,"""training an AI model of the Llama-3.1 scale can produce an amount of air pollutants equivalent to driving a passenger car for more than 10,000 LA-NYC round trips, resulting in a health cost that even exceeds 120 of the training electricity cost.""","The passage from han2024 states the health cost exceeds 120% of the training electricity cost, so the health cost was 120% of the electricity cost."
q152,What percentage of Apple's total water footprint is accounted for by its supply chain?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about Apple’s water footprint or the share of that footprint attributable to its supply chain, so the answer cannot be determined from the given sources."
q154,"What is the total execution time, in seconds, of a sparse BlackMamba model fine-tuned with a NVIDIA A40-48GB with a batch size of 84?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents mention BlackMamba fine-tuning and NVIDIA GPUs, but none specify execution time for a sparse BlackMamba model on an NVIDIA A40-48GB with batch size 84."
q144,True or False: Sustainable deployment techniques described for large language models demonstrated up to a 45% reduction in carbon emissions after quantization.,TRUE,1,is_blank,khan2025,https://arxiv.org/pdf/2504.06307,Experimental results reveal that these methods can reduce energy consumption and carbon emissions by up to 45 post quantization,"The quoted sentence from the khan2025 document states that the deployment techniques, including quantization, can reduce carbon emissions by up to 45%, directly supporting the claim in the question."
q151,"In 2023, what percentage of Amazon's Workforce in the United States across all levels identified as men?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain any information about Amazon’s workforce composition or gender percentages for 2023. Therefore the answer cannot be determined from the provided sources.
q156,"According to a coalition of Microsoft employees, a single deal with Exxon Mobil to expand oil production could add up to how many times more carbon emissions than the company's yearly carbon removal targets?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about a coalition of Microsoft employees, an Exxon Mobil deal, or the comparison to Microsoft's yearly carbon removal targets."
q155,Which metric was introduced to assess the ratio of computation to communication time when scaling distributed training across continents?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain a mention of a metric that assesses the ratio of computation to communication time when scaling distributed training across continents.
q159,How often does the Standing Committee of the One Hundred Year Study form a Study Panel?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain information about the Standing Committee of the One Hundred Year Study or the frequency with which it forms a Study Panel. Thus there is insufficient evidence to answer the question confidently.
q162,True or False: IBM's Watson program did NOT beat human contenders in the Jeopardy challenge.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not mention IBM's Watson, the Jeopardy challenge, or any outcome of a competition between Watson and human contestants. Therefore there is insufficient information to determine whether Watson beat human contenders."
q161,"Based on publicly available data, what is the range of energy consumption, in MWh, to pre-train a large language model (LLM)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain explicit or inferable values for the energy consumption in MWh required to pre‑train a large language model, so the answer cannot be determined from the given context."
q160,"What was the average number of connected devices per U.S. household reported in 2021 (smartphones, laptops, smart TVs, speakers, wearables, gaming consoles, etc)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the average number of connected devices per U.S. household in 2021.
q165,"After model alignment, what MT-Bench score did the JetMoE-8B-Chat model achieve, surpassing the Llama-2-13b-Chat model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts discuss hardware setups, model specifications, and inference experiments but do not contain any information about MT‑Bench scores for JetMoE‑8B‑Chat or Llama‑2‑13b‑Chat. Therefore the answer cannot be inferred with confidence from these documents."
q142,"In 2023, what percentage of the data centers' total electricity cost was their public health cost equivalent to, using the average attribution method?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a clear statement of the percentage of data centers' total electricity cost that their public health cost is equivalent to, using the average attribution method."
q167,How many medium-length GPT-3 completions (prompt= 800 words; response 150-300 words) could be produced with the water required to fill a single 500 mL bottle?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents provide a specific amount of water consumed per GPT‑3 completion (prompt 800 words, response 150‑300 words), so the question cannot be answered with the given information."
q157,"What is the term for freshwater taken from ground or surface sources, either temporarily or permanently, for various uses?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain the definition or term for freshwater taken from ground or surface sources, either temporarily or permanently, for various uses. Therefore, I cannot provide a confident answer."
q172,What percentage of the machine learning (ML) workload is estimated to be inference processing by NVIDIA in 2019?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any statement or data indicating the percentage of machine learning workload that NVIDIA estimated to be inference processing in 2019.
q168,The 2024 Griggs et al. paper reports that Mélange can reduce deployment costs by up to what percentage in conversational chat settings?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided excerpt from the Griggs et al. 2024 paper does not contain any mention of a percentage reduction in deployment costs for conversational chat settings, and none of the other documents discuss this metric. Therefore there is insufficient information to answer the question confidently."
q173,"Throughout the entire 'Power Hungry Processing' (2024) study, what was the total amount of CO2 equivalent emissions generated?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the total CO2 equivalent emissions for the 'Power Hungry Processing' (2024) study, so a confident answer cannot be derived."
q176,"What is the ground truth throughput, in queries/sec, of a dense Mixtral-CS-A100-40GB when the batch size is 1?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain a ground truth throughput value for a dense Mixtral-CS-A100-40GB model at batch size 1.
q169,What is the bare minimum number ofA100 80GB GPUs required to run LLaMA-65B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit statement about the minimum number of NVIDIA A100 80GB GPUs required to run the LLaMA-65B model without compression or quantization. Therefore, I cannot provide a confident answer based solely on the available context."
q171,Training an AI model of the Llama-3.1 scale can produce air pollutants equivalent to how many round trips by car between Los Angeles and New York City?,"more than 10,000 round trips",10000,round trips,han2024,https://arxiv.org/pdf/2412.06288,"""training an AI model of the Llama-3.1 scale can produce an amount of air pollutants equivalent to driving a passenger car for more than 10,000 LA-NYC round trips""","The Han 2024 document explicitly states that training a Llama‑3.1 scale model emits pollutants equivalent to over 10,000 Los Angeles–New York City round trips by passenger car."
q174,True or False: Estimating GPU energy consumption based on its Thermal Design Power (TDP) is a reliable and accurate method.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about estimating GPU energy consumption from Thermal Design Power (TDP) or about its reliability and accuracy, so the answer cannot be determined from the given context."
q175,True or False: GPT-4o mini consumes less energy per query than the larger GPT-4o.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain information comparing the energy consumption per query of GPT-4o mini to the larger GPT-4o model, so a confident answer cannot be derived from the available context."
q177,"True or False: A 2025 paper's analysis shows that after the peak in 2022, the trend of AI developers directly disclosing environmental information for notable models continued to increase.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain a statement indicating that, after a 2022 peak, the trend of AI developers directly disclosing environmental information for notable models continued to increase. Therefore, the answer cannot be determined with confidence from the supplied material."
q180,"Recent reports describe the monthly on-demand rental cost of serving Llama-2-70B at BF16 precision using 2 NVIDIA A100 GPUs. Based on this information, estimate how much it costs per hour to run the model (assuming 30 days/month).",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain a monthly on-demand rental cost for serving Llama‑2‑70B at BF16 precision on 2 NVIDIA A100 GPUs, so the hourly cost cannot be computed from the given information."
q182,"Fetch the amount of CO2 emitted (in lbs) for the training and neural architecture search for a Transformer model. Using that and the emissions-to-driving-distance ratio from a recent study, what is the approximate driving distance in miles that's equivalent to the carbon emissions from training a Transformer model with neural architecture search?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The context provides the CO2 emission for training a Transformer model with neural architecture search (626,155 lbs) but does not include an emissions‑to‑driving‑distance ratio needed to convert that figure into miles. Without that ratio, the driving distance cannot be calculated from the provided documents."
q181,"To achieve a BLEU score increase from 5 to 40 for a GPT-3-based language translation task, how much larger must the model be?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any information linking GPT-3 model size to BLEU score improvements from 5 to 40, so the question cannot be answered with confidence."
q184,How many H100 GPU hours were consumed during the pre-training of the JetMoE-8B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain any information about the JetMoE-8B model or the number of H100 GPU hours used in its pre‑training. Therefore the answer cannot be determined from the supplied context.
q183,"The BLOOMz-7B model was downloaded 606,096 times as of Nov 2023. Based on the inference energy reported for this model, estimate the total energy in MWh that would be consumed if every download resulted in 1 million inferences.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain the inference energy for the BLOOMz-7B model, so the requested calculation cannot be performed with confidence."
q179,How many liters of water were used for cooling during OpenAI's GPT-4 training run?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain a specific figure for the amount of water used for cooling during OpenAI's GPT‑4 training run, so the answer cannot be determined with confidence from the provided information."
q178,"In the Griggs et al. (2024) evaluation of four GPU types, what was the normalized on-demand hourly price for an H100 GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The documents provided do not contain any explicit information about the normalized on-demand hourly price for an H100 GPU in Griggs et al. (2024).
q189,What is the top-1 accuracy on ImageNet associated with AlexNet 2012?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention AlexNet or its ImageNet top‑1 accuracy, so the answer cannot be determined from the provided context."
q188,"Using the throughput data for the final 101B training stage, estimate the total computational work performed during this stage in zettaFLOPs.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any throughput data or computational work figures for the final 101B training stage, so a confident estimate cannot be derived."
q185,"Based on the trend of growing development costs, the largest training runs will exceed what cost by the year 2027?",more than a billion dollars,1000000000,USD,cottier2024,https://arxiv.org/pdf/2405.21015,"""If the trend of growing development costs continues, the largest training runs will cost more than a billion dollars by 2027.""","The passage explicitly states that by 2027, the largest training runs will exceed a billion dollars, which is used to answer the question."
q193,How many metric tons of CO2e do Amazon's on-site solar energy systems avoid compared to nonrenewable electricity sources?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain information about Amazon’s on‑site solar energy systems or the CO2e avoided by them. Therefore the answer cannot be determined from the given context.
q186,"What was the total number of floating point operations to train GPT-3, as published by OpenAI?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the total number of floating point operations used to train GPT-3.
q190,"How many total A800 GPUs, distributed across 24 servers, were used for training the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the number of A800 GPUs used across 24 servers for training the FLM-101B model.
q195,By what factor did energy consumption increase when the Llama 3.1 70B model was deployed on two nodes instead of one?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the energy consumption of the Llama 3.1 70B model deployed on one versus two nodes, so the requested factor cannot be determined from the given context."
q191,"What are the estimated CO2 emissions from performing neural architecture search (NAS) to train a Transformer-based model for machine translation, and how many average American lifetimes is this equivalent to?","626,155 lbs CO₂, equivalent to roughly 17.3 average American lifetimes",626155,lbs,strubell2019,https://arxiv.org/pdf/1906.02243,"""Transformer (big) 192 w/ neural architecture search 626,155"" and ""American life, avg, 1 year 36,156""","The Strubell 2019 table lists the CO₂ emissions for a Transformer model with NAS as 626,155 lbs. Dividing this by the per‑year American life CO₂ consumption of 36,156 lbs yields about 17.3 lifetimes, which is the figure quoted in the answer."
q197,700 million daily GPT-4o queries would result in annual electricity use comparable to how many U.S. homes?,"35,000 U.S. homes",35000,homes,jegham2025,https://arxiv.org/pdf/2505.09598,"Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35000 U.S. homes","The Jegham 2025 article explicitly states that 700 million daily GPT‑4o queries would use enough electricity in a year to power about 35,000 U.S. homes, providing the required figure."
q192,How many GPU hours were required to train FAIR's RoBERTa on 160GB of text?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain information about the GPU hours required to train FAIR's RoBERTa on 160GB of text.
q199,"True or False: In Yelp sentiment analysis benchmarks, traditional models achieved accuracy comparable to large language models.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents discuss Yelp sentiment analysis benchmarks or compare traditional models to large language models, so there is insufficient information to answer the question confidently."
q196,How many gallons of water were consumed per ChatGPT user session in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents provide a numeric value for gallons of water consumed per ChatGPT user session in 2023. The available passages discuss training water usage, overall inference energy, or general water consumption metrics but do not specify the requested figure. Therefore, the answer cannot be derived with confidence from the provided sources."
q187,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-65B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents specify the memory requirement of the LLaMA‑65B model or the number of NVIDIA V100 32GB GPUs needed for inference without compression or quantization, so the answer cannot be determined from the given context."
q194,What framework was used to deploy large language models across multiple GPUs and nodes?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided passages do not contain any explicit statement about a specific framework used for deploying large language models across multiple GPUs and nodes.
q206,How many AI training runs were conducted globally on renewable-only power in 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any information about the number of AI training runs conducted globally on renewable-only power in 2022, so the answer cannot be determined from these documents."
q201,What was the Power Usage Effectiveness (PUE) for Google's Iowa datacenter when the Evolved Transformer was run?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain the PUE value for Google's Iowa datacenter when the Evolved Transformer was run, so the answer cannot be confidently determined from the given context."
q198,"According to a 2025 paper, what was Microsoft's reported percentage increase in global water consumption between 2021 and 2022?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain the reported percentage increase in Microsoft’s global water consumption between 2021 and 2022.
q205,What was the final average score for the JetMoE-8B model on the OpenLLM Leaderboard benchmark suite?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the JetMoE-8B model or its final average score on the OpenLLM Leaderboard benchmark suite.
q210,"In the analysis of KV Cache size growth for the OPT-2.7B model, how large did the cache become for a batch size of 32?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain information about KV Cache size growth for the OPT-2.7B model or its cache size at batch size 32.
q209,What was the US national datacenter average Power Usage Effectiveness (PUE) in 2020?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain any information about the US national datacenter average Power Usage Effectiveness (PUE) for 2020.
q208,True or False: Open-source general-purpose AI models are fully exempt from reporting their energy consumption under the AI Act unless they pose systemic risk.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the AI Act’s reporting requirements for open‑source general‑purpose AI models, so the claim cannot be verified or refuted with the available evidence."
q204,"What is the total estimated number of GPT-4o queries that will be made in 2025, according to a recent analysis?","255,500,000,000",255500000000,queries,jegham2025,https://arxiv.org/pdf/2505.09598,"""Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable...""","The analysis in jegham2025 estimates 700 million GPT‑4o queries per day. Multiplying by 365 days yields approximately 255.5 billion queries for the year 2025, which is the total estimated number of GPT‑4o queries."
q214,"According to an analysis of 100 news articles on ChatGPT's energy use, what percentage cited the popular but contested estimate that a single query is '10 times more than a Google search' or uses '3 Wh'?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied context passages mention a study of 100 news articles on ChatGPT’s energy use or the percentage that referenced the contested estimate. Therefore the information required to answer the question is not present in the provided documents.
q163,One study estimates that how many queries to the GPT-3 model consume approximately half a liter of water?,700 million queries,700000000,is_blank,jegham2025,https://arxiv.org/pdf/2505.09598,"Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35000 U.S. homes, evaporative freshwater equal to the annual drinking needs of 1.2M people","The context indicates that 700 million queries per day to GPT‑3 are the quantity used in the study, and that this quantity is related to the water consumption estimate."
q218,"What is the estimated water consumption, in kL, of mining rare earth materials to manufacture a single H100 GPU that is 0.1% rare earth metal by mass?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the water consumption of mining rare earth materials for an H100 GPU. Therefore, a confident answer cannot be derived from the given context."
q217,True or False: Increasing the number of GPU shards increased the energy cost per response for LLaMA-65B.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention GPU shards or energy cost per response for the LLaMA‑65B model, so the answer cannot be determined from the supplied information."
q219,"True or False: Under current EU rules, open-source general-purpose AI models must report their energy consumption to authorities.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain a statement that under current EU rules open‑source general‑purpose AI models must report their energy consumption to authorities. Therefore the answer cannot be determined from the provided context.
q212,"For the four notable models studied in-depth by Cottier et al. (2025), R&D staff costs (including equity) accounted for what percentage range of the total amortized cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context does not contain a clear percentage range for R&D staff costs relative to total amortized cost for the four notable models studied by Cottier et al. (2025).
q216,What is the name of the function proposed to improve instance selection accuracy by adjusting for discrepancies between theoretical and actual GPU performance?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided excerpts do not contain information about a function that adjusts for discrepancies between theoretical and actual GPU performance, so I cannot determine its name with confidence."
q213,Which software package was used to measure energy consumption during inference runs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context documents do not contain a clear statement of which software package was used to measure energy consumption during inference runs.
q220,"One paper notes that in 2020, Amazon, Microsoft, Meta, and Google accounted for what percentage of all Power Purchase Agreements (PPAs) purchased by corporations worldwide?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided context documents contain any information about the percentage of PPAs purchased by Amazon, Microsoft, Meta, and Google in 2020."
q222,"What was the total public health cost of U.S. data centers in 2023, based on the average attribution method?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not include a specific numeric value for the total public health cost of U.S. data centers in 2023 based on the average attribution method, so the answer cannot be determined from the documents. "
q226,"What is the total execution time, in seconds, of a sparse Mixtral model with a batch size of 1 fine-tuned with a NVIDIA A40-48 GB GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about the execution time of a sparse Mixtral model with batch size 1 fine-tuned on an NVIDIA A40-48 GB GPU.
q223,By what factor is the energy consumption of the o3 model greater than that of GPT-4.1 nano for a long prompt?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain specific energy consumption figures for the o3 model or GPT-4.1 nano for a long prompt, nor do they provide a ratio or factor between them. Therefore the answer cannot be determined from the available context."
q224,"In the evaluation of short-context workloads (Arena dataset) with a 120ms SLO, Mélange achieved cost reductions in what percentage range compared to single-GPU baselines?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about Mélange, the Arena dataset, or cost reduction percentages for short-context workloads with a 120 ms SLO."
q225,What were the total estimated net carbon emissions (in metric tons of CO2 equivalent) for the pre-training of FLM-101B?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain a value for the total estimated net carbon emissions of the FLM-101B pre‑training run.
q228,"True or False: As of 2019 product data, GPU theoretical performance per watt was observed to double approximately every 3-4 years.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about GPU theoretical performance per watt doubling every 3-4 years as of 2019 product data, so the answer cannot be determined from the supplied context."
q235,"According to Chen et al. (2025), what is the price per hour for an NVIDIA H100?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention Chen et al. (2025) or provide the hourly price for an NVIDIA H100, so the information is not available to answer the question."
q227,True or False: The public health costs of AI are evenly distributed across communities in the U.S.,FALSE,0,is_blank,han2024,https://arxiv.org/pdf/2412.06288,"Importantly, the health costs are unevenly distributed across counties and communities, particularly affecting low‑income counties that could experience approximately 200x per‑household health costs than others.","The quoted passage from han2024 explicitly states that the public health costs are unevenly distributed across counties and communities, contradicting the claim that they are evenly distributed. Therefore the statement is false."
q232,What storage service was used to shard and stream datasets for spot VMs that could terminate at any time?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about a storage service used to shard and stream datasets for spot VMs that could terminate at any time.
q234,Which U.S. Senator introduced the AI Environmental Impacts Act bill in February 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided context documents contain information about a U.S. Senator introducing the AI Environmental Impacts Act bill in February 2024, so the answer cannot be determined with confidence from the supplied material."
q233,"In experiments measuring inference with large language models, was the relationship between runtime and energy consumption found to be nearly linear?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied contexts contain a statement about the relationship between runtime and energy consumption in inference experiments for large language models, so the answer cannot be determined from the provided documents."
q236,What was the estimated average GPU lifetime (in years) before retirement in AI data centers in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain a stated average GPU lifetime before retirement in AI data centers for 2024.
q237,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-13B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain information specifying the minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-13B inference without compression or quantization. Therefore the answer cannot be determined with confidence.
q238,"What are the reported GHG emissions (tCO2e) from the pre-training process for Google's Gemma family of language models, and how does this compare to the 'five cars' estimate?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about the GHG emissions from the pre‑training of Google’s Gemma language models or a comparison to the ‘five cars’ estimate.
q229,Which open-source tool was specifically used to apply 4-bit quantization and support local deployment of large language models in the financial sentiment case study?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied contexts explicitly mention an open‑source tool used for 4‑bit quantization and local deployment in the financial sentiment case study. Therefore, there is insufficient information to answer the question with confidence."
q239,How long does it take to train ELMo on 3 NVIDIA GTX 1080 Ti GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents mention the training time for ELMo on 3 NVIDIA GTX 1080 Ti GPUs.
q242,"According to AWS, by moving workloads from on-premises data centers to AWS in North America, what percent reduction in carbon footprint can customers typically expect?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain any mention of AWS or a specific percent reduction in carbon footprint from moving workloads to AWS in North America.
q241,What was the reported PUE of Google's hyperscale data centers in 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain a statement about the PUE of Google's hyperscale data centers in 2021, so the answer cannot be determined from the provided context."
q240,"What is the estimated U.S. national average water consumption for electricity generation, in L/kWh?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a numeric value for the U.S. national average water consumption for electricity generation expressed in L/kWh, so the answer cannot be determined from the documents."
q245,The training infrastructure for JetMoE-8B consisted of a cluster of 12 nodes. How many total H100 GPUs were used for the training?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about JetMoE-8B, its training infrastructure, or the number of H100 GPUs used. Therefore, I cannot determine the total number of H100 GPUs from these sources."
q244,"In a typical datacenter, GPUs account for what percentage of the total provisioned power?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied context passages contain information about the percentage of total provisioned power that GPUs account for in a typical datacenter. Therefore the answer cannot be determined from the provided documents.
q249,What was the approximate speedup in inference throughput for LLaMA-13B when using NVIDIA A100 GPUs compared to V100 GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided contexts describe hardware specifications but do not include any inference throughput measurements or comparative speedup data for LLaMA-13B on NVIDIA A100 versus V100 GPUs. Therefore the question cannot be answered with confidence from the given documents.
q243,What the net cost of fine-tuning a sparse Mixtral model using 2 million queries with NVIDIA H100 GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain specific information about the net cost of fine‑tuning a sparse Mixtral model with 2 million queries on an NVIDIA H100 GPU, nor do they provide the necessary cost figures or computational details to compute such a cost."
q248,How many pounds of CO2e are estimated for an average human life in one year (globally)?,"11,023 lbs",11023,lbs,strubell2019,https://arxiv.org/pdf/1906.02243,"Human life, avg, 1 year 11,023","The Strubell 2019 table lists the CO2e for an average human life in one year as 11,023 pounds, providing the required global estimate."
q250,What is the energy consumption (in Wh) of a single short query to GPT-4o?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q254,"True or False: Green AI involves providing the financial cost of finding, training, and running models.",True,1,is_blank,schwartz2019,https://arxiv.org/pdf/1907.10597,"""we propose reporting the financial cost or price tag of developing, training, and running models to provide baselines for the investigation of increasingly efficient methods.""","The statement is supported by the explicit mention in the Schwartz 2019 document that Green AI includes reporting the financial cost of developing, training, and running models."
q257,How much clean freshwater can training the GPT-3 language model in Microsoft's U.S. data centers directly evaporate?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents includes a specific figure for the amount of clean freshwater that GPT‑3 training in Microsoft’s U.S. data centers directly evaporates, so the answer cannot be derived from the supplied context."
q256,(Multi-step Question) What is the difference in average system power per processor between the TPU v2 and the V100 GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any information about the average system power per processor for either the TPU v2 or the V100 GPU, so a confident answer cannot be derived."
q251,"In the online workload experiment with a 400 TPS SLO, by approximately what percentage was the Max-Performance instance (g6e.xlarge) more expensive than InferSave's top choice?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not include the cost of InferSave's top choice instance or a clear comparison to the Max‑Performance g6e.xlarge instance, so the percentage difference cannot be determined with confidence."
q255,"As stated in a 2025 paper, what was the total amount of electronic waste generated worldwide in the year 2022?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided 2025 paper excerpts do not contain a statement of the total worldwide electronic waste generated in 2022, so the answer cannot be confidently derived from the given documents."
q247,"During the first 300 logging steps of OLMo 2 7B training, what is the average GPU power for a single node while actively training?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about the average GPU power during the first 300 logging steps of OLMo 2 7B training.
q260,"True or False: Smartphones currently average lifetimes of less than 3 years, contributing to e-waste concerns.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention smartphone average lifetimes or related e‑waste statistics, so the statement cannot be verified from the provided context."
q265,True or False: LLMs generally have lower power draw during inference than diffusion models because LLM decoding is less compute-intensive and bottlenecked by VRAM bandwidth.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information comparing the power draw of LLM inference to diffusion models, nor do they discuss decoding being less compute-intensive or bottlenecked by VRAM bandwidth. Therefore there is insufficient evidence to support or refute the statement."
q261,True or False: Intra-zone scaling with T4 GPUs achieved nearly linear per-GPU speedup for CV models.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about intra‑zone scaling with T4 GPUs or their per‑GPU speedup for CV models, so the statement cannot be verified."
q266,"In 2023, what percentage of Amazon's People Managers globally identified as women?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The supplied documents contain no information about Amazon’s People Managers or their gender distribution in 2023.
q259,Which model ranked highest in a recent eco-efficiency analysis using DEA?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided excerpts do not contain a clear statement identifying which specific model achieved the highest rank in the eco-efficiency analysis using DEA.
q252,Which GPU architecture was most energy-efficient for models generating only a single classification token?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain explicit information about which GPU architecture is most energy-efficient for models generating a single classification token, so a confident answer cannot be derived."
q264,"What is the context window size, in tokens, for the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents do not contain any explicit statement or numeric value indicating the context window size (in tokens) for the FLM-101B model. Therefore, a confident answer cannot be derived from the provided material."
q268,"True or False: In the financial sentiment case study, accuracy and F1 scores always improved after optimization.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about a financial sentiment case study or its accuracy/F1 outcomes, so the answer cannot be determined from the given context."
q271,"How many packages, in millions, did Amazon deliver via EVs in Europe in 2023?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about Amazon’s package deliveries via electric vehicles in Europe for 2023.
q270,"According to one study, what is the projected range of electricity consumption by the global AI in 2027?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about the projected range of electricity consumption by global AI in 2027.
q258,How much did Facebook's recommendation and ranking model sizes increase between 2019 and 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any explicit information about the increase in Facebook's recommendation and ranking model sizes between 2019 and 2021.
q267,"When excluding equity, what was the percentage range of total amortized cost attributed to computing hardware for the four key models analyzed by Cottier et al. (2025)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not include the percentage range of total amortized cost attributed to computing hardware for the four key models analyzed by Cottier et al. (2025) when excluding equity, so the answer cannot be determined from the supplied documents."
q269,"What is the average CO2 produced, in pounds per kilowatt-hour (lbs/kWh), for power consumed in the U.S., as provided by the U.S. Environmental Protection Agency (EPA)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain the EPA’s average CO₂ emission factor per kilowatt-hour for U.S. power consumption, so the answer cannot be determined from the supplied context."
q279,"As of January 2024, how many Amazon Renewable Energy Projects were announced in the United States?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain information about Amazon Renewable Energy Projects announced in the United States as of January 2024.
q277,"True or False: In Yelp sentiment analysis benchmarks, traditional models achieved accuracy comparable to large language models.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention Yelp sentiment analysis benchmarks or compare traditional models to large language models, so there is insufficient information to answer the question."
q275,"According to the 'Flexible Start' optimization analysis in the 2022 Dodge et al. paper, what is the maximum potential percentage reduction in CO2 emissions for a short job (DenseNet 201) in the West US region?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context for the 2022 Dodge et al. paper does not include any information about the Flexible Start optimization analysis, the CO2 emissions reduction percentages, or the West US region. Therefore, the documents do not contain enough information to answer the question."
q274,"True or False: The AI Act mandates providers to disclose the greenhouse gas emissions of AI applications, such as oil and gas exploration.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied passages mention the AI Act or any requirement for providers to disclose greenhouse gas emissions for AI applications. Therefore the question cannot be answered with certainty from the provided documents.
q281,What percent of power usage did Amazon's AWS cover with renewable energy in 2018?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any information about the percentage of AWS power usage covered by renewable energy in 2018, so the answer cannot be determined from these documents."
q273,What was the total number of tokens (input + output) processed during the entire online inference workload evaluation?,"1,920,000 tokens",1920000,tokens,kim2025,https://arxiv.org/pdf/2504.11816,"""To model a real-time chatbot system, we use a pattern of 128 input tokens and a 512 output tokens. ... The workload evaluates a total of 3000 requests.""","The Kim2025 document states that each online inference request uses 128 input tokens and 512 output tokens, and there are 3000 requests, so the total tokens processed are (128 + 512) × 3000 = 1,920,000 tokens."
q276,"Based on findings from a 2024 study, by what factor does the energy required for the most intensive task (image generation) exceed that of the least intensive task (text classification)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any explicit comparison of energy consumption between image generation and text classification tasks or a 2024 study reporting such a factor.
q287,How many kilometers of fiber optic cable were installed globally to support AI workloads in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied context passages contain any numeric value or statement about fiber optic cable kilometers installed globally to support AI workloads in 2023, so the answer cannot be determined from the documents."
q285,Serving a Llama2-70b model at BF16 precision requires how many NVIDIA A100-80GB GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied context passages contain information about the number of NVIDIA A100‑80GB GPUs required to serve a Llama2‑70b model at BF16 precision. Therefore the answer cannot be determined from the provided documents.
q284,"In an experiment to train a BERT-base model, what percentage of the total electricity consumption was attributed to the GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents mention a BERT-base training experiment or give a percentage of electricity consumption attributable to the GPU. Therefore the information required to answer the question is not present in the provided context.
q283,At which measurement level do the authors recommend AI energy consumption should be reported to balance accuracy and feasibility?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a clear statement about the recommended measurement level for reporting AI energy consumption. Without explicit evidence, I cannot confidently provide an answer."
q286,What was the total operational energy footprint reduction achieved at Facebook over a two-year period (2019 to 2021) due to iterative hardware-software optimization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any explicit figure or statement describing the total operational energy footprint reduction at Facebook between 2019 and 2021 due to iterative hardware-software optimization. Therefore, a confident answer cannot be derived from the available information."
q289,True or False: The umbrella term 'Sustainable AI' was proposed to only encompass using AI in climate-positive applications.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain a statement about the umbrella term 'Sustainable AI' or its proposed scope, so the truth value cannot be determined from the provided context."
q292,"In its 2024 environmental report, what percentage increase in GHG emissions since 2019 did Google report?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain any information about Google’s 2024 environmental report or its reported percentage increase in GHG emissions since 2019.
q291,"When an LLM inference server is overloaded, which of the two preemption mechanisms-Recomputation or Swapping-consistently consumes less energy?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information comparing the energy consumption of Recomputation versus Swapping in overloaded LLM inference servers.
q295,By approximately what percentage does the JetMoE-8B architecture reduce inference computation compared to the Llama2-7B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention JetMoE-8B or provide a comparison of its inference computation to Llama2-7B, so the requested percentage cannot be determined from the available information."
q293,"According to McKinsey projections, what percentage of U.S. national electricity consumption are data centers anticipated to account for in 2030?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about McKinsey projections for data center electricity consumption in 2030, so the answer cannot be determined from the given context."
q290,What is the ground truth maximum batch size (in samples) for fine-tuning a Mixtral model on a NVIDIA A100-40GB GPU,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit statement or data regarding the maximum batch size for fine‑tuning a Mixtral model on an NVIDIA A100‑40GB GPU, so a confident answer cannot be derived."
q294,"When using the 'Pause and Resume' optimization for training of the 6B parameter transformer, what is the maximum potential emissions saving?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied passages contain information about a 'Pause and Resume' optimization or its emissions savings for a 6B parameter transformer model. Therefore the answer cannot be determined from the given documents.
q302,"True or False: For CV models with high granularity, intercontinental training slowed performance by only 7% compared to local training.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about CV models, high granularity, intercontinental training, or a 7% performance slowdown. Therefore the answer cannot be determined from the supplied context."
q303,How many hectares of land were occupied by new AI data centers globally in 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The available context passages do not contain any information about the land area occupied by new AI data centers in 2022, so the answer cannot be determined from the provided documents."
q288,What is the estimated upfront hardware acquisition cost to train GPT-4?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not specify a precise numeric estimate for the upfront hardware acquisition cost to train GPT‑4, only that it is “tens of millions of dollars.” Therefore the information is insufficient to answer the question with confidence."
q300,"True or False: When enhancing performance of LLM fine-tuning, the Mixture of Experts (MoE) layer is often a targeted layer.",TRUE,1,is_blank,xia2024,https://arxiv.org/pdf/2408.04693,"For QLoRA, we target the MoE layers, including the routers, and set the rank of the LoRA modules to 16.","The context explicitly states that during fine‑tuning (QLoRA) the Mixture of Experts layers are targeted, indicating that MoE layers are a focus when enhancing LLM fine‑tuning performance."
q299,"What was the estimated training energy of the full GPT-3 model, in MWh?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain a specific estimate of the training energy consumption for the full GPT‑3 model in MWh. The context does not provide the required numeric value, so the answer cannot be given with confidence."
q305,"A 2024 study compares task-specific and general-purpose models. How many grams of CO2eq are emitted by the BERT-based model bert-base-multilingual-uncased-sentiment per 1,000 text classification queries?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the CO2eq emissions of bert-base-multilingual-uncased-sentiment per 1,000 queries in a 2024 study comparing task-specific and general-purpose models. Therefore the answer cannot be determined from the supplied context."
q307,"In the experiment analyzing emissions from training a BERT model across different geographic regions, what was the approximate range of CO2 emissions (in thousands of grams) between the most and least efficient regions?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain specific numeric information about CO2 emissions from training a BERT model across different geographic regions, nor do they provide a range of emissions in thousands of grams. Therefore, the answer cannot be determined from the supplied context."
q298,"What was the carbon footprint (in lbs CO2e) of training the BERT large language model, as quantified in a seminal 2019 study?","626,155 lbs CO2e",626155,lbs CO2e,strubell2019,https://arxiv.org/pdf/1906.02243,"""Transformer (big)   192 w/ neural architecture search 626,155""","The Strubell et al. 2019 study lists the carbon footprint for training a Transformer (big) model—BERT large—as 626,155 lbs CO2e, as shown in the quoted table."
q310,How many liters of freshwater did Google's DeepMind AlphaFold servers consume in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention Google DeepMind AlphaFold servers or their freshwater consumption for 2023, so there is insufficient information to answer the question."
q301,What is the maximum batch size (in samples) supported by fine-tuning Mixtral with a dense setup on the Hellaswag dataset using a NVIDIA A40 GPU with 48 GB memory?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain explicit information about the maximum batch size for fine-tuning Mixtral in a dense setup on the Hellaswag dataset using an NVIDIA A40 GPU with 48 GB memory. Therefore, the answer cannot be determined from the given context."
q308,In what year did the practice of directly releasing environmental information for notable models peak before declining?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain information about a peak year for the practice of directly releasing environmental information for notable models.
q309,"What is the equivalent water usage, in days, for one person in the US, of training an OLMo 60M model on 1.7 to 5.6 trillion tokens?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain the specific water usage figures or a conversion to days for training an OLMo 60M model on the stated token ranges, so the question cannot be answered with confidence."
q311,True or False: Adding compute resources to accelerate the MoE layers when fine-tuning LLMs can increase costs.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents explicitly state that adding compute resources to accelerate MoE layers during fine‑tuning increases costs, so the claim cannot be confirmed or refuted with confidence from the given context."
q312,"According to a carbon footprint analysis, what was the total energy consumption for training the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided contexts contain a numeric or descriptive statement about the total energy consumption for training the FLM-101B model. Therefore, the answer cannot be determined from the given documents."
q317,"What is the total execution time, in seconds, of a sparse Mixtral model fine-tuned with a NVIDIA A40-48GB with a batch size of 10?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not include any information about the execution time of a sparse Mixtral model fine‑tuned on an NVIDIA A40‑48GB with a batch size of 10, so the answer cannot be determined from the available evidence."
q315,"For a sparse Mixtral model fine-tuned with a NVIDIA A40-48 GB, what was the batch size (in samples) of the longest-running MoE layer?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context does not contain any explicit mention of a batch size for the longest-running MoE layer in a sparse Mixtral model fine-tuned on an NVIDIA A40-48 GB GPU. Therefore the answer cannot be determined from the available documents.
q318,True or False: GPU-level power consumption monitoring is recommended as the preferred method for reporting overall AI energy use.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents explicitly recommend GPU-level power consumption monitoring as the preferred method for reporting overall AI energy use, so the answer cannot be determined with confidence."
q313,"According to a recent study's projections for 2030, the total public health burden of U.S. data centers could be valued at up to more than what amount?",20 billion dollars,20,billion dollars,han2024,https://arxiv.org/pdf/2412.06288,"The overall public health costs could reach more than 20 billion, rival or even top those of on-road emissions of the largest U.S. states such as California with 35 million registered vehicles.","The document states that the projected public health costs of U.S. data centers could exceed 20 billion dollars, indicating the burden could be valued at more than this amount."
q320,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-7B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents specify the minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-7B inference without compression or quantization.
q319,"In a 2023 article estimating the carbon footprint of the BLOOM model, what percentage of the model's overall emissions did training account for?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any information about a 2023 article estimating the carbon footprint of the BLOOM model or the percentage of emissions attributable to training. Therefore, the answer cannot be determined from the documents given."
q321,"When training GPT-3 in a data center in Arizona, how many user requests would it take to consume a 500ml bottle of water?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain a specific estimate of water usage per user request during GPT-3 training in an Arizona data center, so the question cannot be answered with confidence."
q323,"On the GSM8k benchmark, which evaluates grade school math problem-solving, what score did the JetMoE-8B model achieve?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the GSM8k benchmark score achieved by the JetMoE-8B model, so the answer cannot be determined from the given context."
q314,What is the estimated total cost of fine-tuning a Mixtral model on the GSM8K dataset with sparse MoE with an NVIDIA A40-48GB GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain a numeric estimate of the monetary cost for fine-tuning a Mixtral model on GSM8K with sparse MoE using an NVIDIA A40-48GB GPU.
q322,What is the estimated CO2 emission in metric tons for one year of average US home energy use?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about the CO2 emissions for a typical U.S. household’s annual energy use, so the answer cannot be determined from the provided context."
