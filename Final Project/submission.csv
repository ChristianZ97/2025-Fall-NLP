id,question,answer,answer_value,answer_unit,ref_id,ref_url,supporting_materials,explanation
q001,What was the average increase in U.S. data center electricity consumption between 2010 and 2014?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit figures or statements about U.S. data center electricity consumption for the years 2010 and 2014, so the average increase cannot be determined from the available information."
q004,How many data centers did AWS begin using recycled water for cooling in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about AWS using recycled water for cooling in 2023, so the answer cannot be determined from the given context."
q010,By how many fold did processor clock speed improve between the Intel 4004 (1971) and typical 2021 microprocessors?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain information about the Intel 4004 clock speed or typical 2021 microprocessor clock speeds, so the fold improvement cannot be determined from the supplied context."
q002,"In 2023, what was the estimated amount of cars that could be taken off the road equivalent to the amount of metric tons of CO2e the Amazon Solar Farm Maryland-CPV Backbone would avoid?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The supplied documents do not contain any information about the Amazon Solar Farm Maryland-CPV Backbone or its CO2e avoidance and the equivalent number of cars taken off the road for 2023.
q007,What is the approximate CO2e for a single passenger round trip from San Francisco (SF) to New York (NY)?,1984 lbs,1984,lbs,strubell2019,https://arxiv.org/pdf/1906.02243,"Air travel, 1 passenger, NYSF  1984","The Strubell 2019 document lists the CO2e for a single passenger round‑trip air travel from New York to San Francisco as 1984 lbs, which directly answers the question."
q006,By what factor was the estimated amortized training cost of GPT-4 greater than the total training budget for FLM-101B?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a specific numeric estimate of the amortized training cost of GPT‑4, nor do they provide the precise total training budget value for FLM‑101B in a way that allows calculation of a factor. Therefore the question cannot be answered with confidence from the given context."
q008,"When evaluated on the Open LLM Leaderboard, what was the final average performance score achieved by the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain a statement of the FLM‑101B model’s final average performance score on the Open LLM Leaderboard, so the answer cannot be inferred with confidence."
q012,What is the estimated GPU Power Usage in kWh from SGLang benchmarking on 2400 prompts from ShareGPT at an 8 request/s frequency with a Llama 3.2 1B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about SGLang benchmarking, ShareGPT prompts, or GPU power usage for a Llama 3.2 1B model at the specified frequency."
q013,"What were the total permitted annual emission limits (in tons) for nitrogen oxides from data center backup generators in northern Virginia between January 1, 2023 and December 1, 2024?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about nitrogen oxide emission limits for data center backup generators in northern Virginia for the specified period.
q011,"How many days did it take to train GPT-3 using 10,000 V100 GPUs at 24.6 TeraFLOPS/sec?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the training duration of GPT-3, the number of V100 GPUs used, or the specified performance of 24.6 TeraFLOPS/sec. Therefore, I cannot determine the number of days based on the given context."
q015,Approximately how many premature deaths in 2030 could be caused by scope-2 pollutants from U.S. data centers alone?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents contain a figure for 2028 (1,300 premature deaths) but do not provide a projected value for 2030. Therefore the answer cannot be determined with confidence from the given information."
q016,Dodge et al. (2022) estimate that a full training run of the 6.1 billion parameter model would take approximately how many days?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context for Dodge et al. (2022) does not include any numerical estimate of training time for the 6.1 billion parameter model, so the answer cannot be determined from the supplied documents."
q005,"Since NVIDIA doesn't release the embodied carbon emissions of its hardware, what are the estimated embodied carbon emissions in kg per GPU?",Approximately 18 kg of CO₂ equivalent per GPU.,18,kg,strubell2019,https://arxiv.org/pdf/1906.02243,"Training one model (GPU) NLP pipeline (parsing, SRL) 39","The Strubell et al. table lists 39 lbs of CO₂ equivalent for training one GPU. Converting 39 lbs to kilograms (1 lb ≈ 0.4536 kg) yields roughly 18 kg, which is the estimated embodied carbon per GPU."
q019,"According to the UN's Global E-Waste Monitor 2024, what percentage of e-waste has been formally collected and recycled?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context documents do not contain any information about the UN’s Global E‑Waste Monitor 2024 or the percentage of e‑waste that has been formally collected and recycled. Therefore the answer cannot be determined from the supplied material.
q021,What percentage of the Switch Transformer's 1500 billion parameters are activated per token?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the Switch Transformer, its parameter count, or the percentage of parameters activated per token. Therefore the answer cannot be determined from the given context."
q017,"For the inference process, which model has the highest GPU energy consumption for 1,000 queries among those listed in the appendix of a 2025 study?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit information about GPU energy consumption for 1,000 queries or a list of models with such metrics in an appendix of a 2025 study."
q014,A 2025 paper compares its training time to a from-scratch approach. What percentage of time was saved by using the growth strategy for the 101B model?,90%,90,%,li2025a,https://arxiv.org/pdf/2309.03852,"""FLM-101B, trained with our growth strategy under a budget of 100K, reaches 80 of the baselines' performances with only 10 of their floating-point operations.""","The abstract states that the growth strategy uses only 10% of the floating‑point operations of a from‑scratch baseline, implying a 90% reduction in training time for the 101B model."
q023,"What is the total execution time, in seconds, of a dense BlackMamba model with a batch size of 30 fine-tuned with a NVIDIA A40-48 GB GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the execution time of a dense BlackMamba model fine‑tuned on a NVIDIA A40 GPU with batch size 30, so the answer cannot be determined with confidence."
q022,The JetMoE-8B architecture is a Mixture-of-Experts (MoE) model. How many experts are included in each MoE layer?,8 experts,8,is_blank,xia2024,https://arxiv.org/pdf/2408.04693,Both models incorporate eight experts in their MoE layers.,"The context explicitly states that each MoE layer contains eight experts, which directly answers the question about the number of experts in each layer of the JetMoE-8B architecture."
q018,In what year was the One Hundred Year Study on Artificial Intelligence launched?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain explicit information about the launch year of the One Hundred Year Study on Artificial Intelligence.
q020,What is the energy consumption (in MWh) for pre-training the BLOOM model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit information about the energy consumption (in MWh) for pre‑training the BLOOM model, so a confident answer cannot be derived from them."
q025,Which hardware processor was reported for the experimental setup of energy-efficient local inference in financial sentiment classification?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents mention a hardware processor used for an experimental setup of energy‑efficient local inference in financial sentiment classification. Therefore the answer cannot be determined from the given material.
q027,By what factor does the overall carbon footprint decrease if GPU utilization is increased to 80% for Language Model (LM) training?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any information about how overall carbon footprint changes with GPU utilization levels, so the factor cannot be determined from them."
q024,"According to a cost estimation, how many zettaFLOPs were required to train the English portion of the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any mention of zettaFLOPs or a cost estimation for training the English portion of the FLM-101B model, so the answer cannot be determined from the documents."
q029,What is the estimated total energy consumption (in MWh) for a full training run of a 6.1 billion parameter transformer model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the energy consumption of a full training run for a 6.1 billion parameter transformer model, so the answer cannot be determined from the supplied context."
q031,"By 2027, the global AI demand is projected to account for how many billion cubic meters of water withdrawal?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context excerpts do not contain any statement about the projected global AI demand for water withdrawal by 2027, so the answer cannot be determined from these documents."
q028,Cottier et al. (2025) find that the total compute for model development is how many times larger than the compute for the final training run alone?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a statement or numeric ratio indicating how many times larger the total compute for model development is compared to the compute for the final training run alone. Therefore, I cannot answer the question with confidence."
q026,How many different machine learning models were sampled and analyzed for the 'Power Hungry Processing' (2024) study on AI deployment costs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any reference to a study titled ""Power Hungry Processing"" (2024) or the number of models sampled and analyzed in such a study."
q032,"True or False: As researchers have determined the well-known diminishing returns of increased cost of AI research, Red AI is on the decline.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents discuss environmental impact, compute growth, and cost of AI training, but none mention Red AI or its decline, so the statement cannot be confirmed or refuted with the given information."
q030,The central argument of one 2025 paper is that technical efficiency gains in AI may not lead to net environmental benefits due to what economic principle?,Jevons' Paradox,Jevons' Paradox,is_blank,luccioni2025a,https://arxiv.org/pdf/2501.16548,From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate,The abstract of the 2025 paper explicitly names Jevons' Paradox as the economic principle underpinning the claim that technical efficiency gains in AI may not yield net environmental benefits.
q034,"True or False: At Facebook, a majority of model experimentation workflows utilize GPUs at over 80% capacity.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention GPU utilization percentages for model experimentation workflows at Facebook, so the claim cannot be verified from the provided context."
q033,"Using a growth strategy, what was the total wall-clock time required to train the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a statement or numeric value for the wall-clock time required to train FLM-101B using the growth strategy, so a confident answer cannot be derived from the documents."
q035,How much electricity (in MWh) is the training of GPT-3 estimated to have consumed?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain a numeric estimate of the electricity consumption for training GPT-3 in MWh, so the answer cannot be derived with confidence from the provided context."
q037,"For a dense BlackMamba model with a batch size of 30 fine-tuned with a NVIDIA A40-48 GB GPU, what was the execution time, in microseconds, for the longest kernel of the MoE layer?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about execution times for the longest kernel of the MoE layer for a dense BlackMamba model with the specified batch size and GPU. Hence, the answer cannot be determined from the given context."
q041,"In 2023, in how many of AWS data center regions was 100% of the electricity consumed matched with renewable energy sources?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context documents do not contain any information about AWS data center regions or renewable energy matching for 2023.
q040,What was the reported drop in global carbon emissions in 2020 during the COVID-19 pandemic?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the reported drop in global carbon emissions in 2020 during the COVID‑19 pandemic. Therefore the answer cannot be determined from the given context.
q036,What is the name of the collaborative project that aims to create a standardized method for comparing the inference efficiency of various AI models?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any mention of a collaborative project that creates a standardized method for comparing inference efficiency of AI models.
q042,What is the approximate age of the field of Artificial Intelligence in 2025?,Approximately 13 years,13,years,schwartz2019,https://arxiv.org/pdf/1907.10597,"Since 2012, the field of artificial intelligence has reported remarkable progress on a broad range of capabilities including object recognition, game playing, machine translation, and more.",The passage states the field has been active since 2012; subtracting 2012 from 2025 gives an approximate age of 13 years.
q044,"For the Llama 3.1 8B model, by what percentage does energy use decrease when targeting an average Time Per Output Token (TPOT) of 100 ms instead of minimizing latency?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided contexts do not contain any information about the energy use decrease for the Llama 3.1 8B model when targeting a TPOT of 100 ms versus minimizing latency. Therefore the question cannot be answered with confidence from these documents.
q039,"True or False: deep learning models are increasingly large and computationally-intensive, with a 200,000x increase in the amount of compute used to train them over a six-year span (2012 -2018).",False,0,is_blank,schwartz2019,https://arxiv.org/pdf/1907.10597,"The computations required for deep learning research have been doubling every few months, resulting in an estimated 300,000x increase from 2012 to 2018. The amount of compute used to train deep learning models has increased 300,000x in 6 years.","The document states a 300,000x increase over the 2012-2018 period, which contradicts the 200,000x increase claimed in the question, making the statement false."
q046,"As of 2023, how many gigawatts of energy storage capacity did Amazon hold?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents contain no information about Amazon’s energy storage capacity as of 2023, so a confident answer cannot be derived from them."
q038,"In each layer of the JetMoE-8B model, how many experts are selected for activation (top-k) for a given token?",2 experts,2,is_blank,xia2024,https://arxiv.org/pdf/2408.04693,"For sparse fine‑tuning, only the top two experts are selected for each token.","The document states that in the JetMoE‑8B model’s MoE layers, sparse fine‑tuning activates only the top two experts per token, indicating a top‑k of 2."
q052,How many Amazon electric delivery vans were added in total across 2022 and 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about Amazon electric delivery vans added in 2022 or 2023, so the answer cannot be determined from the available context."
q045,What is the maximum batch size (in samples) supported by fine-tuning BlackMamba with a sparse setup on the GSM8K dataset using a NVIDIA A40 GPU with 48 GB memory?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents specify the maximum batch size for fine‑tuning BlackMamba on GSM8K with a sparse setup on an NVIDIA A40 GPU. Therefore the answer cannot be determined with confidence from the given context.
q049,What was the global average power usage effectiveness (PUE) of AI-dedicated data centers in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any mention of the global average PUE for AI‑dedicated data centers in 2023.
q048,What percentage of AI inference workloads in Asia were powered by coal in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain any information about the percentage of AI inference workloads in Asia powered by coal in 2023. The excerpts focus on training workloads, general environmental impacts, or unrelated conference details, and do not mention geographic or energy‑source breakdowns for inference workloads in 2023."
q051,What are the GHG emissions (in tCO2e) associated with pre-training the Llama 7B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain any mention of the GHG emissions associated with pre-training the Llama 7B model.
q047,The annual carbon emissions from GPT-4o inference are projected to be comparable to the emissions from how many transatlantic flights?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any statement or data indicating how many transatlantic flights the annual carbon emissions from GPT‑4o inference are comparable to. Therefore, the answer cannot be determined with confidence from the documents given."
q043,"The well-known ""five cars"" carbon footprint estimate, originating from a 2019 study, is based on what specific and infrequently performed AI process?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a clear statement linking the 2019 study’s five‑car carbon footprint estimate to a specific AI process, so a confident answer cannot be derived from the documents."
q056,When was the field of Artificial Intelligence officially christened?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the official christening date of the field of Artificial Intelligence, so the answer cannot be inferred from the supplied context."
q058,True or False: Approximately 770 million people worldwide still lack access to a stable supply of electricity.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the number of people lacking access to a stable electricity supply, so the answer cannot be determined from the given context."
q059,How much energy per token did LLaMA-65B consume at a maximum generation length of 512 tokens?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain a value for energy consumption per token for the LLaMA‑65B model at a maximum generation length of 512 tokens, so the answer cannot be determined with confidence from the supplied information."
q057,What is the average water use effectiveness (WUE) for Google's AI-dedicated data centers in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about Google’s AI‑dedicated data centers’ average WUE in 2024.
q050,"During inference, how many of JetMoE-8B's parameters are activated for each input token?",2,2,is_blank,xia2024,https://arxiv.org/pdf/2408.04693,"For dense fine-tuning, all experts are activated, whereas for sparse fine-tuning, only the top two experts are selected for each token.","The context states that in sparse fine‑tuning—used during inference—each token activates only the top two experts out of the eight available, so only 2 experts’ parameters are active per token."
q060,By what percentage was the overall model size of Facebook's second representative recommendation model (RM2) reduced after being quantized from 32-bit to 16-bit numerical representation?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about Facebook's RM2 model size or its quantization from 32‑bit to 16‑bit, so the question cannot be answered with confidence."
q055,How much energy (in Wh) does the o3 model consume for a long prompt?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not specify the energy consumption of an ""o3"" model for a long prompt; it only gives a range for the most energy-intensive models (exceeding 29 Wh). Therefore there is insufficient information to answer the question definitively."
q064,"What is the estimated cost, in USD, of training AI2's Grover on 256 TPU chips for two weeks?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention the cost of training AI2's Grover on 256 TPU chips for two weeks, so the answer cannot be determined from the given context."
q067,What was the average global data center PUE in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the average global data center PUE in 2023, so the answer cannot be determined from the given context."
q063,"True or False: Sparsely activated Deep Neural Networks (DNNs) consume less than 1/10th the energy of large, dense DNNs without sacrificing accuracy.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention sparsely activated DNNs, their energy consumption relative to dense DNNs, or any claim about achieving less than one‑tenth the energy usage without accuracy loss. Therefore the statement cannot be verified from the given context."
q065,What percentage of the running time does the optimizer stage in BlackMamba sparse fine-tuning take with a NVIDIA A40-48GB GPU when the batch size = 1?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context does not contain any information about the optimizer stage percentage for BlackMamba sparse fine-tuning on an NVIDIA A40-48GB GPU with batch size 1.
q053,True or False: Operational environmental impacts of LLMs do not include GHG emissions that arise from servers and data centers using cooling.,FALSE,0,is_blank,jegham2025,https://arxiv.org/pdf/2505.09598,"Results show the most energy-intensive models exceed 29Wh per long prompt, over 65 the most efficient systems. Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35000 U.S. homes, evaporative freshwater equal to the annual drinking needs of 1.2M people, and carbon emissions requiring a Chicago-sized forest to offset.","The excerpt from jegham2025 demonstrates that operational LLM inference includes carbon emissions (GHG) alongside energy and water usage, which encompasses servers and data center cooling. Therefore, the statement that operational impacts do not include such GHG emissions is false."
q071,What percentage of a client device's total carbon footprint is accounted for by its manufacturing?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the proportion of a client device's total carbon footprint attributable to its manufacturing process.
q068,How many wind turbines were directly contracted by Microsoft to power Azure AI clusters in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about Microsoft contracting wind turbines to power Azure AI clusters in 2023, so a confident answer cannot be derived."
q070,How many members comprised the inaugural 2015 Study Panel of the One Hundred Year Study on AI?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the One Hundred Year Study on AI or its 2015 Study Panel. Therefore, I cannot determine the number of members from the available context."
q061,"True or False: A widely cited claim that AI can reduce global GHG emissions by 5-10% is supported by clear, publicly available calculations and sound scientific grounding.",FALSE,0,is_blank,luccioni2025c,https://arxiv.org/pdf/2506.15572,"""misinformation evolving from inaccurate or de-contextualized best‑effort estimates of greenhouse gas emissions.""","The quote from luccioni2025c indicates that estimates of AI’s environmental impact are best‑effort and not based on clear, publicly available calculations, implying the widely cited 5‑10% claim lacks sound scientific grounding."
q069,"In the analysis of total model development costs by Cottier et al. (2025), what percentage of the cost of developing Gemini Ultra was attributed to R&D staff (including equity)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context excerpts from the Cottier document do not contain a specific percentage of R&D staff costs for Gemini Ultra, so the answer cannot be determined with confidence."
q080,True or False: The AlphaGo program defeated the human Go champion.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents discuss AI environmental impacts and do not mention AlphaGo or its victories over human Go champions, so there is no evidence to support a true or false statement."
q072,True or False: A model with more parameters will always consume more energy during inference.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information that confirms or refutes the statement that a model with more parameters will always consume more energy during inference, so the answer cannot be determined with confidence."
q073,True or False: The Study Panel from the 100 Year Study on AI is concerned that AI is an imminent threat to humankind.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention the Study Panel from the 100 Year Study on AI or its stance regarding AI as an imminent threat to humankind, so the answer cannot be determined from the given information."
q074,How many metric tons of CO2 were emitted by OpenAI's API requests in January 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied passages mention OpenAI’s API requests or their CO₂ emissions for January 2024, so the required information is not present in the provided documents."
q079,How many miles is the Earth from the Sun?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The documents provided do not contain any information about the Earth–Sun distance.
q077,"By what factor did the explosive growth in AI drive the increase in AI training infrastructure capacity at Facebook over the 1.5 year period, from Yr1-Q1 (Year 1, Quarter 1) to Yr2-Q2 (Year 2, Quarter 2) between 2019 and 2021?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain specific information about the factor increase in Facebook’s AI training infrastructure capacity between Yr1‑Q1 and Yr2‑Q2 from 2019 to 2021.
q083,"In the offline workload experiment with a 100 TPS SLO, the Max-Performance policy selected an instance that was what percentage more expensive than the one selected by InferSave?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention the Max-Performance policy, InferSave, or a 100 TPS SLO in an offline workload experiment, so the question cannot be answered with confidence."
q076,"What are the reported GHG emissions (tCO2e) from the pre-training process for Meta's Llama 3 family of models, and how does this compare to the 'five cars' estimate?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain information about Meta's Llama 3 GHG emissions or the 'five cars' estimate.
q066," A large-scale service like Google Translate can perform 1 billion queries per day. Using the average energy for a comparable multi-purpose model (Flan-T5-xxl at 0.083 kWh/1k queries), estimate the daily energy consumption in MWh.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The documents do not provide the energy per 1k queries for Flan‑T5‑xxl, so the calculation cannot be justified from the given context."
q085,"What is the range of GPU energy usage for performing 1,000 inference queries, based on the models listed in a 2025 study's appendix?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain the appendix of the 2025 study listing GPU energy usage per inference query, nor does it give the necessary numeric ranges. Therefore the answer cannot be determined from the supplied documents."
q082,"How many H100 GPU hours were required for the entire JetMoE-8B alignment process, which includes both dSFT and dDPO fine-tuning?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about JetMoE-8B alignment, dSFT or dDPO fine‑tuning, nor do they report H100 GPU hours. Therefore the answer cannot be determined with confidence from the supplied context."
q081,What is the name of the batching strategy that reduces idle GPU time by dynamically replacing completed requests with new ones?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any information about a batching strategy that reduces idle GPU time by dynamically replacing completed requests with new ones, so the answer cannot be derived with confidence from the given material."
q084,"The most carbon-intensive model identified in a 2024 study, stable-diffusion-xl-base-1.0, produces how many grams of CO2eq per 1,000 inferences?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any explicit numeric information about the CO2eq emissions of stable-diffusion-xl-base-1.0 per 1,000 inferences, so the answer cannot be determined from the documents."
q092,"What is the name of the LLM inference system developed in the 2025 Chen et al. paper, which uses model-attention disaggregation?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about a 2025 Chen et al. paper or an LLM inference system that uses model‑attention disaggregation, so the answer cannot be determined from the given context."
q090,"In classification experiments on German public administration texts, which model using sentence embeddings achieved the highest accuracy?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about classification experiments on German public administration texts or the accuracy of models using sentence embeddings. Therefore the question cannot be answered with confidence from the given context.
q088,What decentralized PyTorch-based framework was used to enable distributed spot instance training across clouds and continents?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents explicitly mention a decentralized PyTorch-based framework used for distributed spot instance training across clouds and continents, so the answer cannot be determined from the provided context."
q087,What was the gross carbon intensity of energy according to the U.S. average mix in 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain information about the gross carbon intensity of energy for the U.S. average mix in 2021.
q094,What is the total number of parameters in the JetMoE-8B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any mention or specification of the JetMoE-8B model or its parameter count.
q089,What is the proposed term for expanding transparency in AI to include socio-technical aspects and the societal/environmental footprint of a system?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a clear statement of a specific term proposed for expanding transparency to include socio-technical aspects and societal/environmental footprint. Therefore, I cannot confidently provide an answer."
q093,How many parameters does the largest T5 model have?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about the number of parameters in the largest T5 model, so a confident answer cannot be derived from the provided context."
q086,"True or False: Researchers believe that a universal, one-size-fits-all approach to AI ethics and sustainability can be developed.",False,0,is_blank,luccioni2025b,https://arxiv.org/pdf/2504.00797,"""We argue that the efforts aiming to study AI's ethical ramifications should be made in tandem with those evaluating its impacts on the environment, and we conclude with a proposal of best practices to better integrate AI ethics and sustainability in AI research and practice.""","The excerpt from luccioni2025b states that researchers propose best practices for integrating ethics and sustainability, not a universal, one‑size‑fits‑all solution. This contradicts the claim that researchers believe such a universal approach can be developed."
q095,By what percentage did Google's data center water consumption increase from 2021 to 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any specific data or statements regarding Google’s data center water consumption for 2021 or 2022, nor the percentage change between those years. Therefore the answer cannot be determined from the given information."
q101,How many liters of water were returned to communities from Amazon's replenishment projects in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about Amazon’s replenishment projects or the amount of water returned to communities in 2023, so the question cannot be answered with the available evidence."
q100,What fraction of local throughput was achieved for NLP when training was spread across four continents instead of remaining local?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any information about throughput fractions for NLP training distributed across four continents versus local training, so the answer cannot be determined from these documents."
q104,"As reported in a 2025 paper, how many data center GPUs did NVIDIA ship in the year 2024?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any information about NVIDIA’s data center GPU shipments in 2024, so the answer cannot be determined from the documents."
q097,"In the final growth stage of the FLM-101B training, what was the achieved FLOPs utilization percentage?",10%,10,%,li2025a,https://arxiv.org/pdf/2309.03852,"""our model, namely FLM-101B, trained with our growth strategy under a budget of 100K, reaches 80 of the baselines' performances with only 10 of their floating-point operations.""","The abstract of the paper states that FLM‑101B achieved its performance while using only 10% of the floating‑point operations compared to the baselines, indicating a 10% FLOPs utilization in the final growth stage."
q107,"What percentage of the total amortized hardware and energy cost, on average, is attributed to AI accelerator chips?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided excerpts give percentage ranges for server components, cluster-level interconnect, and energy consumption, but they do not include a specific percentage for AI accelerator chips. Therefore the documents do not contain enough information to answer the question with confidence."
q099,"Compared to a CPU server baseline, by what factor can full-stack optimization (including platform-level caching, GPU acceleration, and algorithmic changes) reduce the operational carbon footprint of a Transformer-based universal translation model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain a clear numeric factor describing how much full‑stack optimization reduces the operational carbon footprint of a Transformer‑based universal translation model relative to a CPU server baseline. Hence the answer cannot be determined from the given context.
q108,What is the Power Usage Effectiveness (PUE) for Facebook's data centers?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain a statement or data about Facebook’s Power Usage Effectiveness (PUE).
q098,What were the estimated amortized training costs for OpenAI's GPT-4?,tens of millions of dollars,tens of millions of dollars,is_blank,cottier2024,https://arxiv.org/pdf/2405.21015,"""For key frontier models, such as GPT-4 and Gemini, the most significant expenses are AI accelerator chips and staff costs, each costing tens of millions of dollars.""","The context from cottier2024 explicitly states that GPT-4’s amortized training cost falls in the tens of millions of dollars range, supporting the answer."
q096,What is the name of the emissions metric defined as 'CO₂ emissions per unit of electricity consumed' in the framework for evaluating energy-efficient large language models?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The documents provided do not contain the metric name defined as 'CO₂ emissions per unit of electricity consumed' in the framework for evaluating energy‑efficient large language models.
q109,"What is the acronym of the Finnish project that proposed integrating ethics, sustainability, design, and foresight for inter-disciplinary governance of AI systems?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not mention a Finnish project or its acronym that integrates ethics, sustainability, design, and foresight for inter-disciplinary governance of AI systems."
q103,"True or False: using custom tags with one-shot, zero-shot, and few-shots techniques in source code completion tasks can reduce energy consumption of LLMs.",TRUE,1,is_blank,rubei2025,https://arxiv.org/pdf/2501.05899,"""Our initial results show that the energy consumption of LLMs can be reduced by using specific tags that distinguish different prompt parts.""","The quote from rubei2025 demonstrates that employing custom tags in prompt engineering (which includes one‑shot, zero‑shot, and few‑shot contexts) can reduce the energy consumption of LLMs during source code completion tasks."
q113,A life cycle assessment found that one Amazon Kindle e-reader produces the same amount of CO2 as how many physical print books?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about Amazon Kindle e‑readers, physical print books, or their CO₂ equivalence, so the question cannot be answered with confidence."
q115,What was the energy consumption of the DS Llama 70B model for inference on the FKTG dataset?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided passages do not contain any information about the DS Llama 70B model or its inference energy consumption on the FKTG dataset, so a confident answer cannot be derived."
q110,What were the estimated amortized training costs for Google's Gemini Ultra?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided excerpts do not contain a specific numeric estimate for the amortized training costs of Google's Gemini Ultra. Therefore the answer cannot be determined from the available documents.
q114,"According to a recent study on the public health impacts of AI, by what factor could the per-household health burden from air pollutants in the most affected, economically-disadvantaged communities exceed that in less-impacted communities?",200x,200,is_blank,han2024,https://arxiv.org/pdf/2412.06288,low-income counties that could experience approximately 200x per-household health costs than others.,"The study reports that low‑income (economically disadvantaged) counties could face per‑household health costs roughly 200 times higher than less‑impacted communities, directly answering the factor asked."
q112,What is the EPA's recently tightened primary standard for the annual average limit of PM2.5?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information regarding the EPA's recently tightened primary standard for the annual average limit of PM2.5.
q116,"According to the 2022 paper by Dodge et al., what is the total number of parameters in the large language model they analyzed?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context for the Dodge et al. 2022 paper does not contain any numeric information about the total number of parameters in the analyzed large language model, so the answer cannot be determined with confidence."
q111,True or False: The AI Act requires providers of GPAI models with systemic risk to conduct risk assessments that include environmental risks.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain explicit information about the AI Act’s requirements for conducting risk assessments that include environmental risks for providers of generative AI models with systemic risk. Therefore, the answer cannot be determined with confidence from the given context."
q117,"What phenomenon is described as technological progress improving efficiency, which then results in increased usage and overall resource consumption?",Jevons' Paradox,Jevons' Paradox,is_blank,luccioni2025a,https://arxiv.org/pdf/2501.16548,From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate,"The document titles a section on “Jevons' Paradox,” indicating that the described phenomenon—efficiency gains leading to rebound effects and increased resource use—is Jevons' Paradox."
q119,"According to Table 2 in a 2024 study on AI's power consumption, what is the average energy consumption, in kWh, for performing 1,000 image generation inferences?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a Table 2 from a 2024 study that reports the average energy consumption for 1,000 image‑generation inferences, so the answer cannot be derived from the given context."
q118,How many Meena training runs would use the same total energy as a single full training run of GPT-3?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided contexts contain information about the energy consumption of Meena or GPT-3, so the question cannot be answered with confidence using only the supplied documents."
q122,By what multiplier did Mistral-small's emissions change after optimization in the financial sentiment classification task?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents contain no mention of Mistral‑small, its emissions, or the financial sentiment classification task, so the question cannot be answered from the available information."
q123,"What were the combined training and fine-tuning energy costs in kWh for the BLOOMz-7B model, as reported in the 'Power Hungry Processing' study?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the combined training and fine-tuning energy costs for the BLOOMz-7B model or a 'Power Hungry Processing' study, so the answer cannot be determined from them."
q120,How many pounds of CO2e are estimated for an average American life in one year?,"36,156 lbs",36156,lbs,strubell2019,https://arxiv.org/pdf/1906.02243,"American life, avg, 1 year 36,156","The Strubell 2019 document lists the CO₂e consumption for an average American life per year as 36,156 lbs, directly answering the question."
q125,What is the total number of parameters in the final FLM-101B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain an explicit numeric statement of the total number of parameters in the FLM-101B model, so the answer cannot be determined with confidence."
q121,"According to a recent paper's 2030 projections on the public health impacts of air pollution from U.S. data centers, which county in West Virginia is projected to have the highest per-household health cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any information about specific West Virginia counties or their projected per-household health costs for 2030, so a confident answer cannot be derived from the documents."
q127,"In the 2024 study 'Power Hungry Processing', what was the total amount of energy consumed for all model experimentation and evaluation?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain a reference to a 2024 study titled ""Power Hungry Processing"" or any figure for total energy consumption of all model experimentation and evaluation. Therefore there is insufficient information to answer the question."
q128,"For the BLOOMz-7B model, how many inferences are required for the cumulative energy cost of deployment to equal the initial energy cost of training and fine-tuning?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about BLOOMz-7B, inference counts, or the comparison of deployment energy cost to training and fine-tuning energy cost."
q126,"Fetch the amount of energy (in kWh) required for a full training run of a 6.1B parameter model. Using that information, and using the energy cost of a comparable model (BLOOMz-7B), approximately how many inferences are needed to match this training energy cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit numeric values for the energy consumption (in kWh) of a full training run of a 6.1‑B parameter model nor the energy cost per inference of BLOOMz‑7B, so the question cannot be answered with confidence based on the supplied context."
q129,What dataset name is used for the German nuclear waste site objection texts classified in the experiments?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context excerpts do not contain any mention of a dataset name for German nuclear waste site objection texts, so the answer cannot be determined from these documents."
q131,What percentage of NVIDIA H100 GPUs manufactured in 2024 used recycled rare earth metals?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents mention the percentage of NVIDIA H100 GPUs manufactured in 2024 that used recycled rare earth metals, so the answer cannot be determined from the provided information."
q133,"According to May 2025 data from the API platform OpenRouter, what percentage of LLM token usage occurred through models that did not disclose their environmental impact?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents do not contain any information about OpenRouter token usage statistics or percentages related to environmental impact disclosure. Therefore, a confident answer cannot be derived from the provided material."
q130,How much freshwater (in liters) was consumed by Meta's Llama 3 inference serving clusters in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any specific information about the freshwater consumption of Meta's Llama 3 inference serving clusters in 2024, so a confident answer cannot be derived from the available context."
q137,What was the total carbon emissions (tCO2e) avoided by pruning and quantizing large language models in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain any mention of pruning and quantizing large language models or a quantified total of carbon emissions avoided in 2023.
q134,What is the bare minimum number of NVIDIA A100 80GB GPUs required to run LLaMA-13B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit information about the minimum number of NVIDIA A100 80GB GPUs required to run LLaMA‑13B inference without compression or quantization. Therefore, a confident answer cannot be derived from the available context."
q140,"According to Chen et al. (2025), what is the price per hour for an NVIDIA H20?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not include any information from Chen et al. (2025), so the price per hour for an NVIDIA H20 cannot be retrieved with confidence from the given context."
q138,"In a specific scenario blending A100 and A10G GPUs, what percentage of cost savings was achieved over an A100-only strategy?",44%,44,%,griggs2024,https://arxiv.org/pdf/2404.14527,0.44,"The context for the scenario blending A100 and A10G GPUs contains the value 0.44, which indicates a 44% cost savings compared to an A100-only strategy."
q136,What is the estimated range of CO2 emissions in metric tons for a *complete* training run of a 6.1 billion parameter transformer model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain a clear numeric estimate or range of CO2 emissions in metric tons for a complete training run of a 6.1 billion parameter transformer model. No document supplies the necessary figure or range, so a confident answer cannot be derived."
q145,How many answers were researchers able to collect after reaching out to over 500 authors for their carbon footprint analysis?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any information about researchers reaching out to over 500 authors or the number of answers they collected, so the answer cannot be derived from these documents."
q141,True or False: Most carbon footprint analyses for AI models gather information automatically without needing to contact authors.,FALSE,0,is_blank,is_blank,is_blank,is_blank,"None of the provided documents state that most carbon‑footprint analyses for AI models gather information automatically without contacting authors. The contexts describe surveys and analyses, but do not mention data collection methodology, so the claim cannot be supported."
q143,What is the bare minimum number of NVIDIA A100 80GB GPUs required to run LLaMA-7B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit statement or data indicating the minimum number of NVIDIA A100 80GB GPUs required to run LLaMA‑7B inference without compression or quantization. Therefore, I cannot answer the question with confidence based solely on the supplied context."
q144,True or False: Sustainable deployment techniques described for large language models demonstrated up to a 45% reduction in carbon emissions after quantization.,TRUE,1,is_blank,khan2025,https://arxiv.org/pdf/2504.06307,Experimental results reveal that these methods can reduce energy consumption and carbon emissions by up to 45 post quantization,"The quote from the khan2025 document states that quantization and related deployment techniques can reduce carbon emissions by up to 45%, supporting the true statement."
q147,"Based on the reported training budget and total GPU hours, estimate the approximate cost per H100 GPU-hour for the JetMoE project.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not mention the JetMoE project’s training budget or total GPU hours, so the cost per H100 GPU‑hour cannot be determined from the available information."
q149,How many tokens were used to pre-train the JetMoE-8B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the number of tokens used to pre-train the JetMoE-8B model, so the answer cannot be determined from the given context."
q151,"In 2023, what percentage of Amazon's Workforce in the United States across all levels identified as men?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about Amazon’s workforce composition in 2023, so the answer cannot be determined from the provided material."
q150,"As of January 2024, how many Amazon Renewable Energy Projects were announced in the United Kingdom?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about Amazon Renewable Energy Projects announced in the United Kingdom as of January 2024, so a confident answer cannot be derived."
q142,"In 2023, what percentage of the data centers' total electricity cost was their public health cost equivalent to, using the average attribution method?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a clear statement of the percentage of data centers’ total electricity cost that their public health cost was equivalent to in 2023 using the average attribution method, so the answer cannot be determined from these documents."
q152,What percentage of Apple's total water footprint is accounted for by its supply chain?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any information about Apple's water footprint or the percentage contributed by its supply chain, so the question cannot be answered with confidence."
q154,"What is the total execution time, in seconds, of a sparse BlackMamba model fine-tuned with a NVIDIA A40-48GB with a batch size of 84?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any numerical value or statement regarding the total execution time of a sparse BlackMamba model fine‑tuned on an NVIDIA A40‑48GB with a batch size of 84, so a confident answer cannot be derived from them."
q159,How often does the Standing Committee of the One Hundred Year Study form a Study Panel?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any mention of the Standing Committee of the One Hundred Year Study or the frequency at which it forms a Study Panel, so the answer cannot be determined from the available information."
q132,The actual CO2e for the Evolved Transformer NAS (3.2 tCO2e) is equivalent to approximately how many passengers taking a round trip between San Francisco and New York?,Approximately 4 passengers,4,passengers,strubell2019,https://arxiv.org/pdf/1906.02243,"Air travel, 1 passenger, NYSF 1984","The table in Strubell et al. lists 1984 lbs of CO2 per passenger for a NYSF round‑trip. 1984 lbs ≈ 0.90 tCO2e per passenger. Dividing the 3.2 tCO2e of the Evolved Transformer NAS by 0.90 tCO2e gives roughly 3.6 passengers, which rounds to about 4 passengers."
q156,"According to a coalition of Microsoft employees, a single deal with Exxon Mobil to expand oil production could add up to how many times more carbon emissions than the company's yearly carbon removal targets?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain information about a coalition of Microsoft employees, an Exxon Mobil deal, or the ratio of resulting carbon emissions to yearly removal targets."
q157,"What is the term for freshwater taken from ground or surface sources, either temporarily or permanently, for various uses?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The context passages do not contain the definition or term requested, so there is insufficient information to provide a confident answer."
q148,"When training a Llama-3.1 scale model in Altoona, Iowa, the health cost was what percentage of the electricity cost?",120%,120,%,han2024,https://arxiv.org/pdf/2412.06288,"""resulting in a health cost that even exceeds 120 of the training electricity cost.""","The cited sentence states that the health cost exceeds 120 % of the training electricity cost, indicating the health cost was 120 %. This directly answers the question for Altoona, Iowa under the given context."
q160,"What was the average number of connected devices per U.S. household reported in 2021 (smartphones, laptops, smart TVs, speakers, wearables, gaming consoles, etc)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about the average number of connected devices per U.S. household in 2021.
q161,"Based on publicly available data, what is the range of energy consumption, in MWh, to pre-train a large language model (LLM)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents provide a numeric range of energy consumption in MWh for pre-training a large language model, so a confident answer cannot be derived from the available context."
q155,Which metric was introduced to assess the ratio of computation to communication time when scaling distributed training across continents?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention a metric for the ratio of computation to communication time when scaling distributed training across continents, so the answer cannot be inferred from the given context."
q162,True or False: IBM's Watson program did NOT beat human contenders in the Jeopardy challenge.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about IBM's Watson or its performance in the Jeopardy challenge, so the truth value of the statement cannot be determined from these sources."
q165,"After model alignment, what MT-Bench score did the JetMoE-8B-Chat model achieve, surpassing the Llama-2-13b-Chat model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about JetMoE-8B-Chat, its MT‑Bench score, or a comparison to Llama‑2‑13b‑Chat, so the answer cannot be determined with confidence."
q167,How many medium-length GPT-3 completions (prompt= 800 words; response 150-300 words) could be produced with the water required to fill a single 500 mL bottle?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain a specific water consumption figure for a GPT‑3 completion or a conversion factor that would allow calculation of how many completions can be generated from 500 mL of water. Therefore the answer cannot be determined with confidence from the given information.
q172,What percentage of the machine learning (ML) workload is estimated to be inference processing by NVIDIA in 2019?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain information about NVIDIA’s estimate of the percentage of ML workload that was inference processing in 2019.
q168,The 2024 Griggs et al. paper reports that Mélange can reduce deployment costs by up to what percentage in conversational chat settings?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context from the Griggs 2024 document does not contain any explicit statement about Mélange reducing deployment costs by a specific percentage in conversational chat settings, and no supporting quote or figure is available to substantiate the answer."
q173,"Throughout the entire 'Power Hungry Processing' (2024) study, what was the total amount of CO2 equivalent emissions generated?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the ""Power Hungry Processing"" (2024) study or its CO₂ equivalent emissions, so a confident answer cannot be derived from them."
q169,What is the bare minimum number ofA100 80GB GPUs required to run LLaMA-65B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a specific statement or calculation indicating the minimum number of A100 80GB GPUs needed to run LLaMA‑65B inference without compression or quantization. Therefore, a confident answer cannot be derived from the supplied context."
q176,"What is the ground truth throughput, in queries/sec, of a dense Mixtral-CS-A100-40GB when the batch size is 1?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the throughput of a dense Mixtral-CS-A100-40GB at batch size 1, so the answer cannot be determined from the supplied context."
q175,True or False: GPT-4o mini consumes less energy per query than the larger GPT-4o.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit information about the energy consumption per query for GPT‑4o mini or GPT‑4o, so the question cannot be answered reliably."
q174,True or False: Estimating GPU energy consumption based on its Thermal Design Power (TDP) is a reliable and accurate method.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about estimating GPU energy consumption from TDP or discuss its reliability or accuracy. Therefore, the question cannot be answered with confidence from the given context."
q177,"True or False: A 2025 paper's analysis shows that after the peak in 2022, the trend of AI developers directly disclosing environmental information for notable models continued to increase.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about a 2025 paper analyzing the trend of AI developers disclosing environmental information, nor do they mention a peak in 2022 or subsequent increases in that trend."
q171,Training an AI model of the Llama-3.1 scale can produce air pollutants equivalent to how many round trips by car between Los Angeles and New York City?,"More than 10,000",10000,round trips,han2024,https://arxiv.org/pdf/2412.06288,"training an AI model of the Llama-3.1 scale can produce an amount of air pollutants equivalent to driving a passenger car for more than 10,000 LA-NYC round trips","The context explicitly states that the pollutants from training a Llama‑3.1 model equal over 10,000 LA‑NYC round trips."
q179,How many liters of water were used for cooling during OpenAI's GPT-4 training run?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain a specific numeric value for the liters of water used for cooling during OpenAI's GPT‑4 training run.
q180,"Recent reports describe the monthly on-demand rental cost of serving Llama-2-70B at BF16 precision using 2 NVIDIA A100 GPUs. Based on this information, estimate how much it costs per hour to run the model (assuming 30 days/month).",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any specific monthly on‑demand rental cost for serving Llama‑2‑70B on two NVIDIA A100 GPUs, so the hourly cost cannot be inferred with confidence."
q181,"To achieve a BLEU score increase from 5 to 40 for a GPT-3-based language translation task, how much larger must the model be?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain any information about the relationship between BLEU score improvements and model size for GPT-3-based translation tasks.
q182,"Fetch the amount of CO2 emitted (in lbs) for the training and neural architecture search for a Transformer model. Using that and the emissions-to-driving-distance ratio from a recent study, what is the approximate driving distance in miles that's equivalent to the carbon emissions from training a Transformer model with neural architecture search?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain an emissions‑to‑driving‑distance ratio needed to convert the Transformer model’s CO2 emissions into an equivalent driving distance, so the question cannot be answered with confidence."
q184,How many H100 GPU hours were consumed during the pre-training of the JetMoE-8B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents mention JetMoE-8B or provide any data on H100 GPU hours consumed during its pre‑training. Therefore the answer cannot be determined from the provided context.
q183,"The BLOOMz-7B model was downloaded 606,096 times as of Nov 2023. Based on the inference energy reported for this model, estimate the total energy in MWh that would be consumed if every download resulted in 1 million inferences.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the inference energy consumption of the BLOOMz-7B model, so the requested estimate cannot be derived from the given context."
q178,"In the Griggs et al. (2024) evaluation of four GPU types, what was the normalized on-demand hourly price for an H100 GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context from Griggs et al. (2024) does not include any mention of the normalized on-demand hourly price for an H100 GPU, so the answer cannot be determined from the available documents."
q187,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-65B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents describe the hardware configurations used in experiments but do not specify the minimum number of V100 GPUs needed to run LLaMA-65B inference without compression or quantization. Therefore, the answer cannot be confidently determined from the given information."
q189,What is the top-1 accuracy on ImageNet associated with AlexNet 2012?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the ImageNet top‑1 accuracy of AlexNet 2012, so a confident answer cannot be given."
q186,"What was the total number of floating point operations to train GPT-3, as published by OpenAI?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the total number of floating point operations used to train GPT-3. Therefore, I cannot provide a confident answer from the supplied context."
q188,"Using the throughput data for the final 101B training stage, estimate the total computational work performed during this stage in zettaFLOPs.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context excerpts do not contain any throughput data or computational work figures for the final 101B training stage, so the requested estimate cannot be derived from the documents."
q185,"Based on the trend of growing development costs, the largest training runs will exceed what cost by the year 2027?",more than a billion dollars,1000000000,dollars,cottier2024,https://arxiv.org/pdf/2405.21015,"""If the trend of growing development costs continues, the largest training runs will cost more than a billion dollars by 2027,""","The abstract of cottier2024 explicitly states that, assuming current cost growth, the largest training runs will exceed a billion dollars by 2027, which matches the question’s requirement."
q163,One study estimates that how many queries to the GPT-3 model consume approximately half a liter of water?,700 million queries per day,700000000,queries/day,jegham2025,https://arxiv.org/pdf/2505.09598,"Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35000 U.S. homes, evaporative freshwater equal to the annual drinking needs of 1.2M people.","The study cites that scaling a short GPT‑3 query to 700 million queries per day results in evaporative freshwater comparable to the annual drinking needs of 1.2 million people, implying that roughly 700 million queries consume about half a liter of water each."
q190,"How many total A800 GPUs, distributed across 24 servers, were used for training the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided passages mention the number of A800 GPUs used for training the FLM‑101B model, so the answer cannot be determined from the documents."
q193,How many metric tons of CO2e do Amazon's on-site solar energy systems avoid compared to nonrenewable electricity sources?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents discuss AI and environmental impacts but contain no information about Amazon’s on‑site solar energy systems or CO2e avoided, so the question cannot be answered from the provided material."
q195,By what factor did energy consumption increase when the Llama 3.1 70B model was deployed on two nodes instead of one?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain information about the Llama 3.1 70B model’s energy consumption or any comparison between one-node and two-node deployments, so the factor cannot be determined from the given context."
q196,How many gallons of water were consumed per ChatGPT user session in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents do not contain a specific figure for gallons of water consumed per ChatGPT user session in 2023, so the answer cannot be derived with confidence from the provided context."
q194,What framework was used to deploy large language models across multiple GPUs and nodes?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents mention a specific framework used to deploy large language models across multiple GPUs and nodes.
q199,"True or False: In Yelp sentiment analysis benchmarks, traditional models achieved accuracy comparable to large language models.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain any information about Yelp sentiment analysis benchmarks or a comparison of traditional models with large language models.
q201,What was the Power Usage Effectiveness (PUE) for Google's Iowa datacenter when the Evolved Transformer was run?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the PUE of Google's Iowa datacenter or the Evolved Transformer run. Hence, I cannot provide a confident answer."
q198,"According to a 2025 paper, what was Microsoft's reported percentage increase in global water consumption between 2021 and 2022?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain a statement about Microsoft's reported percentage increase in global water consumption between 2021 and 2022, so the answer cannot be derived from the provided material."
q192,How many GPU hours were required to train FAIR's RoBERTa on 160GB of text?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied context passages do not contain any explicit mention of the GPU hours required to train FAIR's RoBERTa on 160GB of text, so the answer cannot be determined from these documents."
q205,What was the final average score for the JetMoE-8B model on the OpenLLM Leaderboard benchmark suite?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the JetMoE-8B model or its final average score on the OpenLLM Leaderboard benchmark suite, so the answer cannot be determined from the given context."
q197,700 million daily GPT-4o queries would result in annual electricity use comparable to how many U.S. homes?,"35,000 U.S. homes",35000,U.S. homes,jegham2025,https://arxiv.org/pdf/2505.09598,"Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35000 U.S. homes","The document states that 700 million daily GPT‑4o queries (at 0.42 Wh each) equal the yearly electricity of about 35,000 U.S. homes, so that is the directly cited figure."
q206,How many AI training runs were conducted globally on renewable-only power in 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the number of AI training runs conducted globally on renewable-only power in 2022.
q208,True or False: Open-source general-purpose AI models are fully exempt from reporting their energy consumption under the AI Act unless they pose systemic risk.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain any statement about the AI Act’s reporting requirements for open‑source general‑purpose AI models, so the truth value cannot be determined from these sources."
q210,"In the analysis of KV Cache size growth for the OPT-2.7B model, how large did the cache become for a batch size of 32?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about KV Cache size growth for the OPT-2.7B model or its cache size at batch size 32, so a confident answer cannot be derived."
q209,What was the US national datacenter average Power Usage Effectiveness (PUE) in 2020?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about the US national data center average PUE for 2020, so the answer cannot be determined from the given context."
q212,"For the four notable models studied in-depth by Cottier et al. (2025), R&D staff costs (including equity) accounted for what percentage range of the total amortized cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context does not include any information about the percentage range of R&D staff costs for the four notable models studied by Cottier et al. (2025).
q213,Which software package was used to measure energy consumption during inference runs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any mention of a software package used to measure energy consumption during inference runs, so the answer cannot be determined from the given context."
q218,"What is the estimated water consumption, in kL, of mining rare earth materials to manufacture a single H100 GPU that is 0.1% rare earth metal by mass?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information regarding the water consumption of mining rare earth materials for H100 GPUs or the specific 0.1% rare earth metal by mass figure required to compute the estimate.
q214,"According to an analysis of 100 news articles on ChatGPT's energy use, what percentage cited the popular but contested estimate that a single query is '10 times more than a Google search' or uses '3 Wh'?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention an analysis of 100 news articles or the contested estimate of a single query being '10 times more than a Google search' or '3 Wh', so the question cannot be answered from the given context."
q216,What is the name of the function proposed to improve instance selection accuracy by adjusting for discrepancies between theoretical and actual GPU performance?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any mention of a function that improves instance selection accuracy by adjusting for discrepancies between theoretical and actual GPU performance.
q217,True or False: Increasing the number of GPU shards increased the energy cost per response for LLaMA-65B.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about GPU shards or the energy cost per response for LLaMA-65B, so the statement cannot be evaluated."
q204,"What is the total estimated number of GPT-4o queries that will be made in 2025, according to a recent analysis?","255,500,000,000 queries",255500000000,queries,jegham2025,https://arxiv.org/pdf/2505.09598,"Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35000 U.S. homes","The analysis estimates 700 million GPT‑4o queries per day. Multiplying by 365 days yields approximately 255.5 billion queries in 2025, which is the total number requested."
q223,By what factor is the energy consumption of the o3 model greater than that of GPT-4.1 nano for a long prompt?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain explicit energy consumption values for the o3 model or GPT‑4.1 nano on a long prompt, so the factor cannot be determined from these documents."
q220,"One paper notes that in 2020, Amazon, Microsoft, Meta, and Google accounted for what percentage of all Power Purchase Agreements (PPAs) purchased by corporations worldwide?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about PPAs or the specified companies.
q219,"True or False: Under current EU rules, open-source general-purpose AI models must report their energy consumption to authorities.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any clear statement indicating that under current EU rules open‑source general‑purpose AI models must report their energy consumption to authorities. Therefore the answer cannot be determined with confidence from the given material.
q222,"What was the total public health cost of U.S. data centers in 2023, based on the average attribution method?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain a clear numeric value for the total public health cost of U.S. data centers in 2023 using the average attribution method. Therefore, I cannot provide a confident answer."
q224,"In the evaluation of short-context workloads (Arena dataset) with a 120ms SLO, Mélange achieved cost reductions in what percentage range compared to single-GPU baselines?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any mention of the Arena dataset, short-context workloads, a 120 ms SLO, or the corresponding cost‑reduction percentages for Mélange relative to single‑GPU baselines."
q225,What were the total estimated net carbon emissions (in metric tons of CO2 equivalent) for the pre-training of FLM-101B?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain a clear statement of the total estimated net carbon emissions for the pre-training of FLM-101B, so the answer cannot be determined with confidence."
q228,"True or False: As of 2019 product data, GPU theoretical performance per watt was observed to double approximately every 3-4 years.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about GPU theoretical performance per watt doubling every 3‑4 years, so the answer cannot be determined from the provided context."
q227,True or False: The public health costs of AI are evenly distributed across communities in the U.S.,FALSE,0,is_blank,han2024,https://arxiv.org/pdf/2412.06288,"Importantly, the health costs are unevenly distributed across counties and communities, particularly affecting low-income counties that could experience approximately 200x per-household health costs than others.","The document states that public health costs are unevenly distributed, contradicting the claim that they are evenly distributed across communities. Therefore the answer is FALSE."
q226,"What is the total execution time, in seconds, of a sparse Mixtral model with a batch size of 1 fine-tuned with a NVIDIA A40-48 GB GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the execution time of a sparse Mixtral model with a batch size of 1 fine-tuned on an NVIDIA A40-48 GB GPU, so the answer cannot be determined from the given context."
q232,What storage service was used to shard and stream datasets for spot VMs that could terminate at any time?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention a storage service used for sharding and streaming datasets for spot VMs that could terminate at any time, so the answer cannot be determined from the given context."
q235,"According to Chen et al. (2025), what is the price per hour for an NVIDIA H100?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context documents do not contain any information about Chen et al. (2025) or the price per hour for an NVIDIA H100, so the answer cannot be determined from the given material."
q234,Which U.S. Senator introduced the AI Environmental Impacts Act bill in February 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any mention of the AI Environmental Impacts Act bill, its introduction date, or the U.S. Senator who introduced it. Therefore, there is insufficient information to answer the question."
q236,What was the estimated average GPU lifetime (in years) before retirement in AI data centers in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the estimated average GPU lifetime before retirement in AI data centers in 2024.
q237,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-13B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the memory requirements of the LLaMA‑13B model or how many V100 GPUs would be needed for inference without compression or quantization. Therefore, a confident answer cannot be derived from the available context."
q229,Which open-source tool was specifically used to apply 4-bit quantization and support local deployment of large language models in the financial sentiment case study?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any mention of a 4-bit quantization tool or local deployment method used in a financial sentiment case study. Therefore, I cannot identify the tool with confidence."
q238,"What are the reported GHG emissions (tCO2e) from the pre-training process for Google's Gemma family of language models, and how does this compare to the 'five cars' estimate?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the GHG emissions from the pre-training process of Google's Gemma language models or the 'five cars' estimate, so a confident answer cannot be derived from them."
q191,"What are the estimated CO2 emissions from performing neural architecture search (NAS) to train a Transformer-based model for machine translation, and how many average American lifetimes is this equivalent to?","626,155 lbs CO2, equivalent to about 17 average American lifetimes","626155 lbs CO2, 17 lifetimes",is_blank,strubell2019,https://arxiv.org/pdf/1906.02243,"""Transformer (big) 192 w/ neural architecture search 626,155"" and ""American life, avg, 1 year 36,156""","The document lists 626,155 lbs of CO2 for NAS to train a Transformer model, and 36,156 lbs per average American per year. Dividing 626,155 by 36,156 gives roughly 17 years of an average American’s life, which is the requested equivalence."
q239,How long does it take to train ELMo on 3 NVIDIA GTX 1080 Ti GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about training ELMo on 3 NVIDIA GTX 1080 Ti GPUs or the associated training time.
q240,"What is the estimated U.S. national average water consumption for electricity generation, in L/kWh?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The context passages do not provide a specific numeric estimate for U.S. national average water consumption per kWh of electricity generation.
q233,"In experiments measuring inference with large language models, was the relationship between runtime and energy consumption found to be nearly linear?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain information about experiments measuring inference with large language models or the relationship between runtime and energy consumption.
q242,"According to AWS, by moving workloads from on-premises data centers to AWS in North America, what percent reduction in carbon footprint can customers typically expect?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about AWS or the percentage reduction in carbon footprint when moving workloads to AWS in North America.
q241,What was the reported PUE of Google's hyperscale data centers in 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents do not contain any information about Google's hyperscale data center PUE for 2021, so a confident answer cannot be derived."
q244,"In a typical datacenter, GPUs account for what percentage of the total provisioned power?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information regarding the percentage of total provisioned power in a typical datacenter that is attributed to GPUs, so the answer cannot be derived from the provided context."
q245,The training infrastructure for JetMoE-8B consisted of a cluster of 12 nodes. How many total H100 GPUs were used for the training?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not mention JetMoE-8B, H100 GPUs, or the number of GPUs per node, so the total cannot be determined from the available information."
q243,What the net cost of fine-tuning a sparse Mixtral model using 2 million queries with NVIDIA H100 GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents describe model specifications, fine‑tuning procedures, and general GPU cost metrics, but they do not contain any explicit numbers or formulas for computing the net cost of fine‑tuning a sparse Mixtral model with 2 million queries on an NVIDIA H100 GPU. Therefore a confident answer cannot be derived from the available information."
q247,"During the first 300 logging steps of OLMo 2 7B training, what is the average GPU power for a single node while actively training?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any mention of GPU power measurements or the first 300 logging steps of OLMo 2 7B training, so the answer cannot be determined from the available documents."
q248,How many pounds of CO2e are estimated for an average human life in one year (globally)?,"11,023 lbs",11023,lbs,strubell2019,https://arxiv.org/pdf/1906.02243,"Human life, avg, 1 year  11,023","The Strubell 2019 table lists the estimated CO₂e for an average human life over one year as 11,023 pounds, which directly answers the question about a global average."
q252,Which GPU architecture was most energy-efficient for models generating only a single classification token?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the energy efficiency of GPU architectures for models that generate only a single classification token.
q250,What is the energy consumption (in Wh) of a single short query to GPT-4o?,0.42 Wh,0.42,Wh,jegham2025,https://arxiv.org/pdf/2505.09598,"Even a 0.42Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35000 U.S. homes...","The Jegham 2025 document explicitly states that a single short query to GPT‑4o consumes 0.42 Wh, which directly answers the question."
q255,"As stated in a 2025 paper, what was the total amount of electronic waste generated worldwide in the year 2022?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided excerpts from the 2025 papers do not include any numeric statement or mention of the total amount of electronic waste generated worldwide in 2022, so the answer cannot be determined from the given documents."
q249,What was the approximate speedup in inference throughput for LLaMA-13B when using NVIDIA A100 GPUs compared to V100 GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The supplied documents do not include any specific inference throughput measurements or speedup values for LLaMA‑13B on NVIDIA A100 versus V100 GPUs.
q256,(Multi-step Question) What is the difference in average system power per processor between the TPU v2 and the V100 GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the average system power per processor for TPU v2 or V100 GPU, so the difference cannot be determined from the available context."
q254,"True or False: Green AI involves providing the financial cost of finding, training, and running models.",True,1,is_blank,schwartz2019,https://arxiv.org/pdf/1907.10597,"""In addition, we propose reporting the financial cost or price tag of developing, training, and running models to provide baselines for the investigation of increasingly efficient methods.""","The quoted passage from schwartz2019 explicitly states that Green AI involves reporting the financial cost of developing, training, and running models, directly supporting the true answer."
q251,"In the online workload experiment with a 400 TPS SLO, by approximately what percentage was the Max-Performance instance (g6e.xlarge) more expensive than InferSave's top choice?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any explicit cost comparison between the Max-Performance instance (g6e.xlarge) and InferSave's top choice for the 400 TPS SLO online workload experiment, nor does it provide the percentage difference needed to answer the question."
q260,"True or False: Smartphones currently average lifetimes of less than 3 years, contributing to e-waste concerns.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The supplied documents do not contain any explicit statement or data indicating that smartphones currently average lifetimes of less than 3 years. Therefore the answer cannot be determined with confidence from these sources.
q257,How much clean freshwater can training the GPT-3 language model in Microsoft's U.S. data centers directly evaporate?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a specific figure for the amount of clean freshwater that the GPT-3 training in Microsoft's U.S. data centers directly evaporates, so the answer cannot be determined from the given information."
q261,True or False: Intra-zone scaling with T4 GPUs achieved nearly linear per-GPU speedup for CV models.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain information about intra-zone scaling performance with T4 GPUs for computer vision models, so the statement cannot be verified from the given context."
q264,"What is the context window size, in tokens, for the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the context window size, in tokens, for the FLM-101B model."
q258,How much did Facebook's recommendation and ranking model sizes increase between 2019 and 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context passages do not contain any explicit numeric information about the increase in Facebook's recommendation and ranking model sizes between 2019 and 2021. Without such evidence, a confident answer cannot be provided."
q265,True or False: LLMs generally have lower power draw during inference than diffusion models because LLM decoding is less compute-intensive and bottlenecked by VRAM bandwidth.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the supplied documents contain information about the relative power draw of LLMs versus diffusion models, nor do they discuss VRAM bandwidth bottlenecks. Therefore the question cannot be answered with confidence from the provided context."
q259,Which model ranked highest in a recent eco-efficiency analysis using DEA?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents explicitly name a specific model as the highest-ranked in the DEA eco-efficiency analysis, so the answer cannot be determined with confidence."
q266,"In 2023, what percentage of Amazon's People Managers globally identified as women?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about Amazon's People Managers or the percentage of women among them in 2023, so a confident answer cannot be derived."
q269,"What is the average CO2 produced, in pounds per kilowatt-hour (lbs/kWh), for power consumed in the U.S., as provided by the U.S. Environmental Protection Agency (EPA)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain the EPA’s average CO2 emissions per kWh for U.S. power consumption, so the answer cannot be determined from the given context."
q268,"True or False: In the financial sentiment case study, accuracy and F1 scores always improved after optimization.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any mention of a financial sentiment case study or any information about accuracy or F1 scores improving after optimization. Therefore, the question cannot be answered with confidence."
q271,"How many packages, in millions, did Amazon deliver via EVs in Europe in 2023?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents do not contain any information about Amazon’s package deliveries via electric vehicles in Europe for 2023, so the answer cannot be determined from the provided context."
q275,"According to the 'Flexible Start' optimization analysis in the 2022 Dodge et al. paper, what is the maximum potential percentage reduction in CO2 emissions for a short job (DenseNet 201) in the West US region?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided excerpts from the Dodge et al. 2022 paper do not contain the specific percentage reduction for DenseNet 201 in the West US region under the Flexible Start optimization. Therefore, there is insufficient information to answer the question confidently."
q273,What was the total number of tokens (input + output) processed during the entire online inference workload evaluation?,"1,920,000 tokens",1920000,tokens,kim2025,https://arxiv.org/pdf/2504.11816,"""To model a real-time chatbot system, we use a pattern of 128 input tokens and a 512 output tokens. This simulates a common AI LLM chatbot scenario... The workload evaluates a total of 3000 requests.""","The online inference workload uses 128 input and 512 output tokens per request, totaling 640 tokens per request. Multiplying by 3000 requests gives 640 × 3000 = 1,920,000 tokens processed."
q270,"According to one study, what is the projected range of electricity consumption by the global AI in 2027?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any information about a projected range of electricity consumption by global AI in 2027, so the answer cannot be determined with confidence from these documents."
q274,"True or False: The AI Act mandates providers to disclose the greenhouse gas emissions of AI applications, such as oil and gas exploration.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any statement about the AI Act requiring disclosure of greenhouse gas emissions for AI applications, so the truth value cannot be determined from the given context."
q281,What percent of power usage did Amazon's AWS cover with renewable energy in 2018?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about Amazon AWS renewable energy coverage in 2018.
q277,"True or False: In Yelp sentiment analysis benchmarks, traditional models achieved accuracy comparable to large language models.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents mention Yelp sentiment analysis benchmarks or compare traditional models to large language models, so there is insufficient information to answer the question."
q279,"As of January 2024, how many Amazon Renewable Energy Projects were announced in the United States?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied context documents contain no information about Amazon Renewable Energy Projects announced in the United States as of January 2024, so the answer cannot be determined from the provided material."
q267,"When excluding equity, what was the percentage range of total amortized cost attributed to computing hardware for the four key models analyzed by Cottier et al. (2025)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided context does not contain a clear statement of the percentage range of total amortized cost attributed to computing hardware when excluding equity for the four key models analyzed by Cottier et al. (2025).
q276,"Based on findings from a 2024 study, by what factor does the energy required for the most intensive task (image generation) exceed that of the least intensive task (text classification)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided context does not contain any explicit information about the energy required for image generation versus text classification, so the requested factor cannot be determined from these documents."
q287,How many kilometers of fiber optic cable were installed globally to support AI workloads in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about the amount of fiber optic cable installed globally for AI workloads in 2023.
q285,Serving a Llama2-70b model at BF16 precision requires how many NVIDIA A100-80GB GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the number of NVIDIA A100-80GB GPUs required to serve a Llama2-70b model at BF16 precision. The available contexts mention Llama2-7b or LLaMA 65B but do not provide the requested data.
q286,What was the total operational energy footprint reduction achieved at Facebook over a two-year period (2019 to 2021) due to iterative hardware-software optimization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any specific numeric information about Facebook’s operational energy footprint reduction between 2019 and 2021 due to iterative hardware‑software optimization.
q290,What is the ground truth maximum batch size (in samples) for fine-tuning a Mixtral model on a NVIDIA A100-40GB GPU,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents specify the maximum batch size for fine‑tuning Mixtral on an NVIDIA A100‑40GB GPU. The context only lists model parameters, memory consumption, and training setup details, but does not include a numeric batch size value."
q284,"In an experiment to train a BERT-base model, what percentage of the total electricity consumption was attributed to the GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any statement that specifies the percentage of total electricity consumption attributed to the GPU in a BERT-base training experiment. No relevant figure or table is present in the excerpts to support an answer.
q283,At which measurement level do the authors recommend AI energy consumption should be reported to balance accuracy and feasibility?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided excerpts do not contain any statement specifying the measurement level at which AI energy consumption should be reported. Therefore, I cannot determine the authors’ recommendation with confidence."
q292,"In its 2024 environmental report, what percentage increase in GHG emissions since 2019 did Google report?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contextual documents do not contain any information about Google’s 2024 environmental report or the percentage increase in GHG emissions since 2019. Therefore, the answer cannot be determined from the given sources."
q293,"According to McKinsey projections, what percentage of U.S. national electricity consumption are data centers anticipated to account for in 2030?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the supplied documents contain information about McKinsey projections for data center electricity consumption in 2030.
q294,"When using the 'Pause and Resume' optimization for training of the 6B parameter transformer, what is the maximum potential emissions saving?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents contain no mention of the 'Pause and Resume' optimization, a 6B parameter transformer, or any emissions savings figure related to it, so the answer cannot be determined from the provided material."
q291,"When an LLM inference server is overloaded, which of the two preemption mechanisms-Recomputation or Swapping-consistently consumes less energy?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any information about the energy consumption of recomputation versus swapping when an LLM inference server is overloaded, so the answer cannot be determined with confidence."
q295,By approximately what percentage does the JetMoE-8B architecture reduce inference computation compared to the Llama2-7B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about JetMoE‑8B, Llama2‑7B, or their inference computation comparisons, so the requested percentage reduction cannot be determined from the supplied material."
q289,True or False: The umbrella term 'Sustainable AI' was proposed to only encompass using AI in climate-positive applications.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit statement about the definition or scope of the umbrella term 'Sustainable AI', so the truth value of the claim cannot be determined from the given context."
q299,"What was the estimated training energy of the full GPT-3 model, in MWh?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a numeric estimate of the training energy for the full GPT-3 model in MWh, so the answer cannot be determined from the given context."
q300,"True or False: When enhancing performance of LLM fine-tuning, the Mixture of Experts (MoE) layer is often a targeted layer.",True,1,is_blank,xia2024,https://arxiv.org/pdf/2408.04693,"For QLoRA, we target the MoE layers, including the routers","The context from xia2024 explicitly states that during fine‑tuning, the MoE layers are targeted, confirming the statement."
q301,What is the maximum batch size (in samples) supported by fine-tuning Mixtral with a dense setup on the Hellaswag dataset using a NVIDIA A40 GPU with 48 GB memory?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain explicit information about the maximum batch size for dense fine-tuning of Mixtral on Hellaswag with an NVIDIA A40 GPU, so a confident answer cannot be derived from them."
q303,How many hectares of land were occupied by new AI data centers globally in 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The supplied excerpts do not contain any explicit figure or statement about the hectares of land occupied by new AI data centers globally in 2022.
q302,"True or False: For CV models with high granularity, intercontinental training slowed performance by only 7% compared to local training.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied context passages do not contain any information about CV models with high granularity, intercontinental training, or a 7% performance slowdown, so the statement cannot be verified or refuted from the provided documents."
q298,"What was the carbon footprint (in lbs CO2e) of training the BERT large language model, as quantified in a seminal 2019 study?","626,155 lbs CO2e",626155,lbs CO2e,strubell2019,https://arxiv.org/pdf/1906.02243,"Transformer (big)   192 w/ neural architecture search 626,155","The 2019 Strubell et al. study provides a table of carbon emissions for training various NLP models. The entry for a large transformer (which includes BERT large) lists 626,155 lbs CO2e, giving the required value."
q288,What is the estimated upfront hardware acquisition cost to train GPT-4?,tens of millions of dollars,tens of millions of dollars,is_blank,cottier2024,https://arxiv.org/pdf/2405.21015,"For key frontier models, such as GPT-4 and Gemini, the most significant expenses are AI accelerator chips and staff costs, each costing tens of millions of dollars.",The cited passage from the cost model paper explicitly states that the upfront hardware acquisition cost for GPT-4 is on the order of tens of millions of dollars.
q307,"In the experiment analyzing emissions from training a BERT model across different geographic regions, what was the approximate range of CO2 emissions (in thousands of grams) between the most and least efficient regions?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts do not contain any numeric data or statements about CO2 emissions for BERT training across geographic regions, so the requested range cannot be determined from the documents."
q308,In what year did the practice of directly releasing environmental information for notable models peak before declining?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the peak year of the practice of directly releasing environmental information for notable models, nor do they mention a decline. Therefore the answer cannot be determined with confidence from the given context."
q305,"A 2024 study compares task-specific and general-purpose models. How many grams of CO2eq are emitted by the BERT-based model bert-base-multilingual-uncased-sentiment per 1,000 text classification queries?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the CO2eq emissions of bert-base-multilingual-uncased-sentiment per 1,000 text classification queries, so the answer cannot be determined from the given context."
q312,"According to a carbon footprint analysis, what was the total energy consumption for training the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain a numeric value for the total energy consumption of training the FLM-101B model, so a confident answer cannot be given."
q309,"What is the equivalent water usage, in days, for one person in the US, of training an OLMo 60M model on 1.7 to 5.6 trillion tokens?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied documents do not contain specific numeric values for the water consumption of training an OLMo 60M model on the stated token ranges, nor do they provide a conversion to person-days of water usage. Therefore the answer cannot be determined from the given information."
q310,How many liters of freshwater did Google's DeepMind AlphaFold servers consume in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any information about the freshwater consumption of Google's DeepMind AlphaFold servers in 2023.
q311,True or False: Adding compute resources to accelerate the MoE layers when fine-tuning LLMs can increase costs.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,The provided documents do not contain any explicit statement indicating that adding compute resources to accelerate MoE layers when fine-tuning LLMs increases costs. Therefore the answer cannot be determined from the given context.
q314,What is the estimated total cost of fine-tuning a Mixtral model on the GSM8K dataset with sparse MoE with an NVIDIA A40-48GB GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents describe Mixtral model specifications, dataset details, and fine‑tuning setup, but they do not include any information on GPU rental costs, training duration, or cost calculations for an NVIDIA A40-48GB GPU. Consequently, there is insufficient data to estimate the total fine‑tuning cost."
q313,"According to a recent study's projections for 2030, the total public health burden of U.S. data centers could be valued at up to more than what amount?",20 billion,20,billion U.S. dollars,han2024,https://arxiv.org/pdf/2412.06288,overall public health costs could reach more than 20 billion,"The excerpt from the study states that the overall public health costs could reach more than 20 billion, directly answering the question about the projected value for 2030."
q315,"For a sparse Mixtral model fine-tuned with a NVIDIA A40-48 GB, what was the batch size (in samples) of the longest-running MoE layer?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents mention the batch size for the longest‑running MoE layer of a sparse Mixtral model fine‑tuned on an NVIDIA A40‑48 GB GPU.
q319,"In a 2023 article estimating the carbon footprint of the BLOOM model, what percentage of the model's overall emissions did training account for?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided contexts (luccioni2023, morrison2025, strubell2019) do not contain any information about the 2023 carbon footprint estimation of the BLOOM model or the training percentage of its emissions."
q318,True or False: GPU-level power consumption monitoring is recommended as the preferred method for reporting overall AI energy use.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"None of the provided documents contain a statement indicating that GPU-level power consumption monitoring is recommended as the preferred method for reporting overall AI energy use, so the answer cannot be determined with confidence."
q320,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-7B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any explicit information about the minimum number of NVIDIA V100 32GB GPUs needed to run LLaMA‑7B inference without compression or quantization. Therefore, I cannot provide a confident answer."
q322,What is the estimated CO2 emission in metric tons for one year of average US home energy use?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,None of the provided documents contain information about the CO2 emissions for one year of average U.S. home energy use.
q323,"On the GSM8k benchmark, which evaluates grade school math problem-solving, what score did the JetMoE-8B model achieve?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the GSM8k benchmark score achieved by the JetMoE-8B model, so it cannot be answered with confidence."
q317,"What is the total execution time, in seconds, of a sparse Mixtral model fine-tuned with a NVIDIA A40-48GB with a batch size of 10?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The provided documents do not contain any information about the fine‑tuning execution time for a sparse Mixtral model on an NVIDIA A40-48GB with batch size 10, so the answer cannot be determined with confidence."
q321,"When training GPT-3 in a data center in Arizona, how many user requests would it take to consume a 500ml bottle of water?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,"The supplied contexts do not provide any information on the water consumption per user request for GPT‑3 training in Arizona, nor do they give a conversion from water usage to 500 ml bottles. Consequently, the question cannot be answered with confidence from the provided documents."
